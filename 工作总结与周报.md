

---

工作总结[2025-03-31]

1、改进和梳理了一下CAD绘图Agent工作流的输入模块讨论的材料与问题

2、对接吴晶晶那边讨论清楚了第一版输入流的框架，基于已有的材料和讨论的结果来重新整理一下输入流开发文档

工作总结[2025-04-01]

1、整理完成的模板输入对接方案发送给了开发团队和吴晶晶那边。然后参加AI周例会讨论开发规划

2、下午深入的去调研并设计了一下输入流的网站开发的最小可行技术栈有哪些以及开发框架初步设计

工作总结[2025-04-02]

1、基于之前讨论的初版输入CSV模板来设计用户的交互系统，结合学习使用streamlit框架来搭建这个交互的界面。这部分目前遇到的难点是利用streamlit库与sqlite数据库进行交互，还得补充学习一下基础的数据库操作

工作总结[2025-04-03]

1、写了一下今年第一季度的工作总结，对过去内容所有的日志和周总结做了一个回顾，发现一季度所有内容调研与开发都是相辅相成的，无论是熟悉crew框架还是开发重计量agent都是方便后续开发优秀的生图智能体，这块得一步步来深度求索

2、继续调试了一下streamlit开发的交互模块，目前可以在线编辑部分模板信息，但是多通讯柜情况自定义情况还要进一步设计调试；其次是完成第二次AI培训的考试测试

【2025.03.31-04.03 周工作总结】

- 与吴晶晶团队对齐了核心字段定义，完成了CAD绘图Agent输入流框架V1.0开发文档；
- 已经基于Streamlit搭建了初步的web交互系统原型，并实现在线模板编辑基础功能；但数据动态加载这部分还有问题，多通讯柜自定义交互及Streamlit-SQLite数据联动问题待研究突破。
- 完成一季度技术复盘（框架调研/Agent开发深度耦合验证）。

【本周计划】

1. 推进Streamlit交互模块多模板场景的调试，解决数据库动态加载的技术难点，以及对输入流接口特殊或者异常处理机制完善
2. 把初步具备交互能力的web开放测试，检查是否有输入逻辑错误，其次联系吴晶晶那边确认web设计是否合适

---





工作总结[2025-04-07]

1、review了一下上周智能生图web开发代码状态和问题，最后发现在线编辑模板表格数据会出现重置的情况是因为streamlit的数据更新节点的问题

2、我重新完全重写构造了一下与数据库交互的数据更新逻辑函数，初步解决了数据更新重置的问题。虽然现在在线编辑不重置了，但是我发现现在编辑任一表格都会导致最后一个表格sheet被编辑指令覆盖。这个现在还需要调试一下原因

工作总结[2025-04-08]

1、解决了在线表格编辑时候最后一个tab页会被修改的问题，主要是data_editor内部函数的闭包问题导致数据更新内容错误，我利用AI重写了一下data_editor的回调函数解决了这个问题。现在在线编辑基本没有错误了

2、参与AI组周例会

3、深入讨论了一下交互模块的设计思路，后面需要简化交互逻辑，减少项目信息录入的步骤，调整数据验证板块到数据预览板块上，方便用户修改迭代

工作总结[2025-04-09]

1、把交互web模块做了精简化，不需要项目信息填写与存储，只保留数据预览与在线编辑，目前交互的第一页也就是功能重点就在上传预览与编辑上；其次即是生成预览的结果页面

2、模板选择与示例数据功能仅作为必要下载模板时的补充选项，不再影响用户第一时间即为预览的需求；校验与预览合在一个页面板块，但是这里目前遇到些问题，校验提示都有，但是标红方式出不来，得研究下streamlit对css嵌入方法的应用

工作总结[2025-04-10]

1、重新用CSS与JS来编写了一下校验错误提示的标识信息，解决了标识更新不及时等问题；并分析补充了端口负载、柜号唯一性、类型验证等校验方法实现，初步完善校验体系

2、和曦哥开会讨论了一下从CSV模板到json数据的对接情况，讨论明确了我需要挑选并转化哪些数据结构，以及曦哥需要补充修改哪些JSON内容；然后初步尝试搭建了一下ELK接口与CAD生成的接口api

工作总结[2025-04-11]

1、参加RAG第二期培训，这次从最底层的向量角度看清楚了检索与嵌入存储的细节，感觉能优化研究的内容很多

工作总结[2025-04-12]

[勤奋时间][09:00][17:09]

今天是AI培训的第二期RAG专题学习第二天，今天主要对文本切分、嵌入、向量数据库有了全面的了解，然后深入实践学习了一下检索和提问优化的技巧与知识

【2025.04.07-04.12 周工作总结】

- 基本完成数据模板输入与检验模块。主要攻克了交互模块修复数据更新重置与表格覆盖问题，基于CSS/JS实现基于自定义规则动态校验提示；
- 精简了Web交互流程。合并校验/预览页面；并完善端口负载/柜号唯一性等10项校验规则；
- 跟曦哥确认并推进CSV-JSON数据结构对齐；参与RAG二期培训掌握文本切分/向量检索核心技术链路。

【本周计划】

1. 完成JSON数据结构转化模块开发，实现与曦哥那边ELK接口联调
2. 学习并调研基于ezdxf库的DXF编写方法
3. 实践RAG培训成果，完成大作业





---

工作总结[2025-04-14]

1、分析并重新整理了CSV-JSON数据结构转换的设计与改进；以及图框分割逻辑的初步设计与可能的问题分析汇总。

2、通过《关于csv-json数据结构转换对接及图框拆分设计方案讨论》内部会议确定了，数据转换调整与规范统一的标准，其次确定了分割图框的逻辑，后端处理生成判断再由前端处理管理机原子单元的JSON拆分合并。具体细节与更改内容我也通过会议纪要方式传达了。

工作总结[2025-04-15]

1、探索了一下章阁人才公寓电能管理系统结构图_t3.dwg的错误问题，主要是因为图纸的新比例设置导致的问题，这部分需要CAD数据爬取的时候带上比例缩放的数据；然后参加AI周例会

2、初步调了一下重计量CAD代码对坐标量纲动态适应，在章阁人才公寓电能管理系统结构图上没问题了，但后面还是需要比例缩放的数据

3、同步了最新的JSON模板和数据，然后初步尝试了解析CSV并进行JSON模板的转换，这部分还要进一步映射数据层级的关系并调试

工作总结[2025-04-16]

1、初步解决了主控层与通讯层的JSON转化与连接表示，然后设备层的区分直连与管理机连的转换配置还有点bug需要进一步联合通讯层的屏柜号调试

2、初步实践了一下第三次大作业，做了一点简单尝试用langchain写text2sql，并对生成的sql进行评价与建议，这需要对数据库有一定的学习了解

工作总结[2025-04-17]

1、主要是完成AI培训的第三次大作业，利用langchain框架搭建了一个text2sql的工作流，核心是优化好langchain的sql生成/sql优化prompt模板，让LLM能够理解用户意图生成sql并提供sql校验与优化建议。在此之外配合AI学习并深入理解sqlite和数据库表结构在AI中的的用法

2、重新思考并设计了一下JSON模板的图框范围拆分问题，明天需要开会确定下JSON结构的单位拆分对象以及精确的拆分点

工作总结[2025-04-18]

1、再次评审确定下JSON结构的单位拆分对象以及精确的拆分点，主要是达成团队的拆分逻辑共识；然后完成总结会议纪要

2、按照分图框的逻辑共识来设计相应的代码设计规范，重新从表格数据梳理通信柜分组，然后结合组网结构来设计新的JSON分块模板的逻辑



【2025.04.14-04.18 周工作总结】

- 完成了开发整个CSV到完整JSON数据结构转化标准制定及代码转换逻辑实现，但需要进一步预处理划分CSV
- 协助解决了上周设计院同事反应的图纸比例量纲适配问题，新增实现重计量CAD动态坐标量纲解析；
- 完成AI培训第三次大作业，搭建Text2SQL工作流并优化LangChain提示模板。
- 确定了新的多图框JSON划分方案，通过会议共识明确通信柜分组规则与JSON分块模板；

【本周计划】

1. 推进JSON新图框拆分模块代码开发，完成3组模拟通信柜联调测试
2. 对接并调试开发ELK布局对单图框JSON输入的接口





---

工作总结[2025-04-21]

1、初步完成代码逻辑调试开发，根据通信柜作为图框基础分组，然后对组内数据进行预处理生成单机单网的小的JSON模块。同步的也改进了一下CSV输入示例模拟数据，模拟端口通道数超出12上限的情况

2、对于双机双网的情况比较复杂，因为涉及到交换机与设备层的冗余，索引与匹配方式需要再进一步研究如何处理

工作总结[2025-04-22]

1、研究并初步调试处理了在非单机单网情况下，交换机在各个图框JSON块中的冗余表达，但是在分割多个图框的时候对象添加还需要理一下。目前在环网和双网的处理上可能还需要讨论对齐一下主控层在首图框或者所有图框中的表达方式

2、此外初步调试了一下双网情况下去除管理机部分的非必要的冗余，需要研究一下或者讨论新的切分图框中管理机的数据结构

工作总结[2025-04-23]

1、参加部门AI第三次关于Agent的培训，除了学习听讲师的Agent介绍和经验分享，自己也动手用豆包和coze的平台简单实验了写作的agent工作流，实现起来确实很快但是约束也多，没法进一步的精细调优

2、继续调试CAD分图的代码，现在变量有点多，后面尝试把程序的流程在细化整理一下

工作总结[2025-04-24]

1、进一步梳理并讨论了关于cad分图过程中设备层的交换机与管理机的冗余处理问题，以及主控层的放置问题，并在会议中同团队达成共识

2、重新梳理了关于excel表格的解析代码实现方法，后面在原有数据的基础上重新构建改进数据结构的schema并优化json 的拼接方式，避免将Excel数据直接映射为嵌套字典，应通过明确的数据模型转换实现。方便未来的灵活扩展与维护

工作总结[2025-04-25]

1、上午去体检

2、下午深入的去理解schema数据模型，并根据实际的验证后的表格数据去完善和修改它。

3、完成了完整的表格schema结构搭建，并调试表格解析。同时初步研究并调试使用新的数据结构模型去处理分图数据结构

【2025.04.21-04.25 周工作总结】

- 完成了单机单网场景下通信柜分组与JSON分块生成模块开发，支持12+端口超限预警；
- 讨论并达成双网冗余场景主控层表达共识，优化Excel解析逻辑实现Schema数据模型的转换；
- 参与AI Agent培训并验证低代码平台局限性，明确深度定制开发必要性。
- 完善了新数据模型及布局结构的Schema扩展性，并初步完成分图算法在新数据模型上的迁移；

【本周计划】

1. 推进双机双网交换机冗余逻辑及图框分割对象动态管理实现落地，构建3组复杂组网示例数据完成测试
2. 开展调试开发循环调用布局的接口程序及接口RESTful方案设计



---

工作总结[2025-04-27]

1、总结并整理完成CADDrawerAgent的交互与调度模块、生图模块的阶段规划与里程碑的详细文档设计

2、团队会议讨论后续开发的项目记录与管理安排

3、整理了一下专注于交互与调度模块的已完成与待规划项信息，并补充了相关的材料与汇报和备注

工作总结[2025-04-28]

1、调试并解决了分图算法中直连设备重复计算通道数的测试情况，这部分现调整为按直连设备类型属性来分组计算是否满足10个一列

2、参加AI小组例会；回顾梳理之前的前端和后端代码

工作总结[2025-04-29]

1、JSON分图方法测试初步通过了单机单网、双机双网、单/双光纤环网这些测试数据的情况，同时调整了单网络架构也同样输出commConnections结构

2、设计了初版的ELK模块的接口api与对应参数文档，并做了初步的参数调试

工作总结[2025-04-30]

1、调试并解决了CsvInfo对象一直识别错误的问题，主要不同的导入方式在python中被识别为不同的CsvInfo类型对象

2、测试通过了web前后端的ELK模拟接口，可实现从下载输入excel到分图JSON的列表，再到ELK接口循环输入。



【2025.04.27-04.30 周工作总结】

- 完成了绘图Agent交互模块的链路开发：
  - 解决了CsvInfo对象类型识别问题
  - 跑通Excel输入-分图JSON列表生成-ELK接口循环调用的测试验证路径；
- 通过对环网场景的excel调试优化了分图算法在通道分组上的逻辑；
- 设计了ELK模块接口API及参数文档，目前已测试通过一些比较简单的单/双机双网及环网的模拟录入数据用例

【本周计划】

1. 推进ELK接口对接并最终完成模拟联调，衔接交互输入模块到ELK布局模块
2. 初步调研CAD图纸绘制的技术内容与难点





---

工作总结[2025-05-06]

1、完善对在线录入的excel情况的进行分图JSON列表的稳定性和规则校验，主要包括图框索引规则、柜设备完整性、分图唯一性、控制层展示规则这些，确认分图算法的稳定性

2、除了输入的示例excel情况，还补充了设定阈值的边界测试情况，同样包括以上校验规则。初步测试无问题

工作总结[2025-05-07]

1、梳理并优化整个界面与绘图调度模块，调整项目代码结构方便演示展示

2、展示讨论了交互部分的进展，后面与曦哥对接联调ELK布局的单机单网api换掉现有的模拟占位api

工作总结[2025-05-08]

1、处理frameindex与controllayer和cont_commConnection的显示关系，保留每个框的主控信息。并同步更新主控层分图的校验规则

2、重构了API的请求处理逻辑，调整之前的模拟API成真实ELK模块API的返回参数结构一致，增强处理API返回错误时的处理和保存功能

3、讨论确定分图后各通信柜的主控确认关系，这部分主控与交换机连接不再显式配置，由ELK模块确定连接

工作总结[2025-05-09]

1、重构了项目代码中录入excel数据模型，中关于主控层的连接属性信息，不再自定义配置连接交换机，让ELK代码生成链接

2、更新测试ELK的api展示功能到web界面交互与调度端，目前可以把分图后返回的布局svg部分能展示到预览框中，实时观测录入数据与布局的变化对应关系，但svg显示会有截断的情况，svg容器大小需确定以统一预览框尺寸



【2025.05.06-05.09 周工作总结】

- ELK模块集成取得关键进展： 完成了与ELK布局API的对接联调，替换了原有模拟接口，并适配了其数据结构与处理逻辑。
- 数据处理与校验优化： 完善了Excel在线录入至分图JSON的算法及校验规则，并根据ELK的需求重构了数据模型，提升了稳定性。
- 前端功能初步实现： 实现了ELK返回的SVG布局在Web端的实时预览，并优化了前端代码结构。

【本周计划】

1. 解决SVG预览显示问题： 优化SVG在预览框中的显示，确保完整性和统一尺寸。
2. 协同曦哥深化ELK联调与测试： 扩展到环网与双网的测试场景，配合解决现有预览中布局异常的问题。
3. 调研绘图模块的技术路线、和相应的技术实验，周四15号出一个技术调研文档方便后续进一步讨论方案与分工安排

---



工作总结[2025-05-12]

1、上午重新调试调整了一下svg展示的容器显示，并梳理了当前项目情况与进展

2、对新的绘图模块进行初步的了解，确认有哪些mvp研发是必须的信息以及可能的难点，方便后续的完成dxf生成的技术实验

工作总结[2025-05-13]

1、调研梳理了ezdxf在绘制CAD图纸内容上技术文档与方法

2、结合之前输入给elk的json来尝试制造一个简单的模拟组态绘制的json输入数据示例

工作总结[2025-05-14]

1、主要是尝试解决了本地AutoCAD打开dxf无法显示图元的问题，这块目前实验出来的的原因大概是测试JSON数据属性缺失导致的AutoCAD无法识别元素

2、结合今天从曦哥那拿到的简单的布局坐标和导出的template.dxf的模型空间的信息来重新构建了含关键信息的数据，目前可以显示从输入JSON数据到图形的显示了，但还是有部分元素的缺失需要进一步改进测试数据

工作总结[2025-05-15]

1、跑通从构造的JSON测试用例数据中分别绘制block、line、text、frame这些图元属性，并正常显示生成的dxf

2、初步结合交互模块的metadata与elk布局简单的单机单网JSON数据构建新的真实测试用例，还需要调整结合到新的绘图输入JSON结构中

工作总结[2025-05-16]

1、构建了新的交互分图、ELK布局、图元库对象三个输入数据的schema数据模型，完成了从输入schema到绘图JSON的固定工作流转化

2、尝试手动修正部分图元的坐标的偏移，但是图元与多段线之间还是有偏移对不上，需要分析一下处理方法



【2025.05.12-05.16 周工作总结】

- DXF绘图模块取得初步突破： 成功调研并实验了ezdxf库，实现了从构造的JSON数据（含图块、线条、文字等基本图元）生成DXF文件，并解决了初期图元无法在AutoCAD中正确显示的问题。
- 绘图数据流构建与整合： 定义了交互分图、ELK布局及图元库对象三方输入数据的Schema模型，并初步完成了将这些输入数据转化为绘图模块所需JSON格式的固定工作流。
- 前端显示优化： 调试并优化了SVG预览容器的显示效果，并同步梳理了当前项目整体情况与进展。

【本周计划】

1. 解决DXF图元坐标偏移问题： 重点分析并修复当前DXF生成中图元与多段线之间存在的坐标偏移及对不齐问题，确保绘图准确性。
2. 完善和扩展测试用例： 进一步完善和扩展测试用例，优化绘图输入JSON的结构与内容完整性。研究并实验更复杂图元（如特定设备符号、连接关系等）的绘制方法，为支持更丰富的图纸内容做准备。
3. 固化并优化数据转换工作流： 补充测试用例，并根据测试结果持续优化绘图逻辑，提升DXF文件绘制效果质量

---

工作总结[2025-05-19]

1、调试更新图元库的基点计算方法，使用block的边界框左下角作为基点，这样就可以统一标准统计特殊图元及文本的偏移点。其次虽然观察到部分图元其中构成元素以左上作为基点，但是实验了左上角作为基点会导致大部分block偏离比较大

2、基于block的边界框标准可以统计所有用到的图元块的大小尺寸，这样可以我这边先把统计的模板图元尺寸给到ELK布局生成准确的block区域以及端口位置，这样等ELK返回的坐标应该是更准确

工作总结[2025-05-20]

1、上午梳理讨论绘图技术实验进度与问题，以及参加AI小组周例会

2、下午调研并实验解决了dxf转dwg的技术问题。解决了传统pyautocad频繁出现 COM 错误，无法初始化acad应用问题；win32com库的client方法SAVEAS转换功能总是失效的问题，改进并融合两个传统库的功能实现了基于AutoCAD客户端的dxf转换。但是pyautocad 自 2015 年起未更新，在高版本（包括 2024）中存在严重的兼容性问题，有时候还是会初始化失败

3、因此调研了并部署跑通了第三方ODA的方法，该外部工具有人维护的，可以较快且稳定的调出并转换dxf，因此会作为首选的部署的转换方法

工作总结[2025-05-21]

1、更新了绘图程序中图框和设备块的类型筛选处理逻辑，从ELK结构中获取cadName属性匹配图元库来实现简化结构化的dxf绘制工作流。

2、实现了特殊图元，如交换机、PDU电源等组合符号的插入绘制功能

3、解决了坐标系和偏移的自动修正、实现了从表格输入与模板信息中获取并自动添加图框与图元属性的功能

4、基本跑通从Excel输入到dwg输出的工作流框架，并进行了简单的演示。

工作总结[2025-05-22]

1、解决了手动配置分图JSON列表数据以及ELK布局输出数据的问题。自动化配置路径以及入参结构为绘图模块所适用的JSON模板数据信息

2、把绘图模块的所有功能进行了梳理整合。统一绘图模块的自动化pipline，实现完整的绘图模块的端到端绘图流程：多入参数据加载 -> schema解析 -> 绘图JSON数据生成 -> 坐标修正 -> dxf绘图

工作总结[2025-05-23]

1、协同ELK布局模块解决了图元插入在dxf绘制的坐标修正以及图元CAD插入点的问题，基本调通了一个dxf大致准确布局的案例

2、将坐标转换与基点修正算法部分内容从原始项目中隔离了出来并交给ELK布局去处理

3、初步在项目代码里面跑通了，绘图模块批量处理来自前端模块与ELK模块的列表JSON数据，不再用手动修改文件测试，实现了Excel到批量生成dxf的数据流管线，下一步就可以集成到前端的API界面，实现跑通web端到端绘图文件生成



【2025.05.19-05.23 周工作总结】

- 核心绘图流程打通与格式转换突破： 成功实现了从Excel输入到DWG输出的端到端工作流（并借助第三方ODA工具稳定转换DXF为DWG）。具体完成了绘图模块内部从多源数据加载、Schema解析、绘图JSON生成至DXF绘制的自动化处理管线整合。
- 绘图精度提升： 通过统一图元基点计算、与ELK协同优化坐标修正（坐标转换与基点修正逻辑已移交ELK处理），成功调试出布局基本准确的DXF案例；同时增强了特殊图元（如交换机、PDU）的绘制及图框图元属性的自动填充能力。
- 批量处理与API集成准备就绪： 实现了绘图模块对来自前端及ELK模块的列表JSON数据的批量处理能力，不再依赖手动修改文件测试，为下一步API集成实现Web端到端文件生成奠定了坚实基础。

【本周计划】

1. 完成绘图模块与前端API的集成：实现Web端从Excel上传到DXF文件生成的完整在线闭环。
2. 优化完善自动化生成： 补充针对批量处理和真实业务场景的充分测试，持续优化模块自动化的管线及系统稳定性。
3. 探索dxf上的图框整合算法： 研究整合算法的控制对象，探索控距算法的实现



---

工作总结[2025-05-26]

1、调研了一下ezdxf中整合多个dxf 的msp方法，主要是就是copy所有entity的信息到新的dxf的msp中，但是现在还没能解决的问题，可以整合多个dxf 的信息，但是新的block的属性值不能与block进行绑定，导致排列整合效果可以出现，但是属性值都会堆积在第一个框中。现在的难点就是如何控制属性值的排列的偏移

2、尝试了获取原始block的信息去重新赋值entity的属性值，但是这里面目前还有问题。获取的块确实已经导入到 master_doc.blocks 但 add_entity 仍然返回 None，感觉copy方法获取的结果指示该块定义本身在 master_doc 中是无效的

工作总结[2025-05-27]

1、上午讨论了绘图Agent的进展与后续计划，然后参与AI小组周例会

2、下午主要是完成了AI培训的第六七八次项目作业的源代码学习与总结，并将个人学习是实践的结果记录到作业的文档中完成作业上传；另外是第九次作业使用langchain生成测试用例的workflow也初步利用AI辅助完成了一个简化版的根据需求文档生成测试用例的AI工作流，听从刘总的指导深入的配合协同AI快速完成AIasCoworker的练习实践

3、下午另外也初步尝试了使用所有JSON的列表数据来生成一个大的dxf，但是这个设计的文件数据信息比较多，开发还是碰到不少bug需要后面再快速去调试解决

工作总结[2025-05-28]

1、上午完成了作业九与作业十测试智能助手的langchain框架workflow的搭建，进一步锻炼了利用AI的能力快速完成简单项目搭建、AI协同测试与调试的能力

2、下午重构了用于解析多绘图模块与ELK模块以及dxf模板信息JSON的函数，然后从数据模型上重新构建对多图框列表JSON的解析与排列坐标的搭建，接受排列间距与图框尺寸等等配置生成多图框绘图的输入JSON文件。

3、初步手动调试跑通输入多个图框测试JSON地址生成一个完成的大dxf绘图

工作总结[2025-05-29]

1、调试并整合了绘图模块新的全局数据生成、大dxf绘制的新启动脚本，并完成将ODA转换脚本接入到模块工作流中，手动测试通过从多个绘图输入JSON到全局转换的大DrawingData列表对象生成dxf，最后到DWG最终的输出

2、完成将新的全局DWG生成工作流替换原始旧的多个单图框dxf压缩包的前端API接口，完整实现了在前端web即可通过Excel生成单一大DWG文件

工作总结[2025-05-30]

1、调试修改drawing_data_generator类，解决了特殊块如PDU接入ELK坐标跟随图框生成

2、重新整理了所有配置项包括分图验证、布局参数、ELK结构配置和文件路径等参数到统一的全局文件中，解决了不同脚本配置修改不一致的问题避免了ELK输出的画幅不一致

3、加入了原始的场站安装位置信息到schema和cad_schema结构中并生成相应的全局布局偏移坐标给到ELK模块，目前已经取消了本地实验的全局布局偏移并将全局偏移实现方法移交给了ELK计算。可以稳定生成全局布局的多图框DWG



【2025.05.26-05.30 周工作总结】

- 多图框合并输出单一大DWG功能web上线： 成功实验攻克并实现了将多个独立图框数据的整合。生成单一、大型DWG文件（并集成了ODA进行格式转换）。目前此功能已上线并替换原有前端占位API，用户现可通过Web界面从Excel直接生成统一的DWG图纸（172.17.6.100:5000）。
- 全局布局与配置管理优化： 通过与ELK模块协同（给出具体偏移量到ELK），实现了多图框DWG的稳定全局定位（各行图框位置对齐）。同时，统一了项目各项配置管理在一个脚本中调控，提升了系统稳定性。并优化了特殊图元（如PDU）在ELK坐标系下的定位逻辑。
- AI技能深化与应用： 完成了公司安排的AI培训作业五六七八九十，特别是在LangChain框架构建智能应用（如测试用例生成、智能助手）的实操写代码大作业，锻炼了利用框架搭建AI辅助开发与测试的经验。

【本周计划】

1. 完善单一大DWG文件内容：添加场站信息到绘图的cad_schema，根据对齐的每行图框添加左侧相对的场站说明
2. 研究counterPro与绘图模块的数据对接：调整当前测试Excel数据结构，补充真实测试数据转换需要的信息。最终建立外部的转换工作流管线
3. 补充针对批量处理和真实业务场景数据的充分测试，持续优化模块自动化的管线及系统稳定性。

---

工作总结[2025-06-09]

1、调试解决了Excel中设备类型与设备数量互换后校验模块异常的问题，修正了decode_form中对新schema的解析匹配方法，包括设备属性结构、通讯柜映射关系及配套校验规则的修改与验证

2、解决了之前测试阶段参数预设与属性硬编码的问题，如新增了对通讯/通信柜或箱等字符的兼容支持，避免了莫名其妙的整个图框的设备识别不到的问题

3、构造测试了陕西榆林数据需要分图的情况，发现能够稳定支持分图后对页数与页次的动态排序，暂时没发现bug

工作总结[2025-06-10]

1、测试构建完整的陕西榆林需要分图情况的测试数据，验证通过了存在分图下的图框排序与行索引的计算规则

2、配合ELK排除解决了管理机图元的channelIndex不从1开始的情况，重新修改完整的测试数据，解决了部分端口跑到管理机上方的问题

工作总结[2025-06-11]

1、梳理并调整CAD生图的项目代码与材料，完整演示当前在单机单网上的生成效果，介绍当前项目的特点与未来的展望

2、修复了web 上先预览才能生成DWG的工作流流程

3、初步整理了一部分的深圳平湖智创园项目的双机双网的情况的真实测试数据

工作总结[2025-06-12]

1、补充完第一个构造的深圳平湖智创园项目的双机双网情况的真实测试数据

2、整理CAD生图材料，完成主持对设计院同事的第一次会议项目演示与交流，总结会议内容与后续改进

3、配合布局解决端口通道合并的配置问题

工作总结[2025-06-13]

1、更新智能绘图初步效果演示评审会议的会议纪要为模板格式，进一步整理设计分院的同事的所有会议现场问题与我们的回复

2、修正构建的双机双网数据中双网的结构化连接，构造了一版双机单网连接的简化测试数据。

3、单独测试多组图框JSON发现12通道作为合并阈值比较极限，后续会采取设置合并配置为11通道；同时测试发现直连设备多情况下会有多余的伸出线，已配合ELK解决。另外反复调试了双交换机情况下丢失直连通道的情况，发现主要是ELK目前暂时不支持第二交换机的结构

【2025.06.09-06.13 周工作总结】

- 数据结构重构完成并优化校验模块： 完成了模板数据结构的重构及相应校验的修正，提升了系统对真实数据（如"通讯/通信柜"等）的兼容性与鲁棒性，优化通道合并阈值（11通道）；
- 测试完善单机单网绘图代码并顺利演示：陕西榆林16图框项目100%通过分图场景测试，实现页次动态排序零异常；并成功面向设计院同事完成了项目首次演示与交流，收集了关键反馈，为后续优化指明了方向。
- 启动双机双网复杂场景适配工作： 以“深圳平湖智创园”项目为蓝本，初步完成了双机双网真实测试数据的构建，并基于测试对直连设备划分、连接线等细节进行了优化，正式开启对更复杂组网场景的适配研发。

【本周计划】

1. 解决双机双网支持问题：与曦哥对接，共同设计并推动解决“第二交换机”复杂布局结构的支持，并基于后面初步测试反馈，继续完善和修正双机双网测试Excel数据，以及改进对新复杂数据模型的解析与构建等上层逻辑。

2. 跟进上周演示会议反馈的绘图优化建议：整理并分析设计院同事提出的问题与建议，尝试新增统计数据表格或标注、安装位置与端口标注等。另外上线单机单网部分的功能到钉钉给吴晶晶团队试用


---

工作总结[2025-06-16]

1、整理优化了单机单网的处理工作流代码，移除了后面双机双网的相关数据schema结构以及代码影响

2、修改了录入模板，收集了目前测试图纸中常见的设备类型名称并加入到template_info.json中进行绘图匹配，目前可以支持下拉框选项限定模板里面设备层和通信层设备类型选型，方便约束输入设备不兼容的情况

3、找出了下载模板录入报错的问题，主要是下拉框Excel与agGrid组件不兼容，增加了在输入前进行Excel校验处理解决了预览的前端bug问题

工作总结[2025-06-17]

1、调试搬到43服务器上的绘图项目代码，现在服务器上的软件配置以及代码环境基本调好了，再解决一下agGrid表格显示又出现不兼容的情况基本就没问题了

2、参与AI小组例会

工作总结[2025-06-18]

1、解决了服务器上的agGrid的css与js远程CDN样式远程访问造成延时高的问题，服务器防火墙禁用端口的问题，解决了服务器的中文编码乱码问题

2、单机单网绘图功能已稳定部署到43服务器上，解决了环境的问题，同时也完成上线了钉钉工作台CADDrawerAgent，解决了钉钉开发平台的配置问题，现在可快速访问并生成CAD图纸

工作总结[2025-06-19]

1、更新了Excel模板中通信柜的设备层中设备图元的可选项，支持后续用户自定义和扩展设备块的库的图元类型

2、改写了通讯层交换机的JSON结构，现已支持第二交换机的直连设备数据结构。

3、新增了对上线43服务器和钉钉的CADDrawerAgent应用的使用说明文档，包括界面使用和详细的表格填写说明与注意

4、参与项目发货Agent的细化讨论会议

工作总结[2025-06-20]

1、优化了一下43服务器上绘图和交互两个模块的工作流代码，去除了多余的测试代码和实验性的调试代码，确保方便代码的易读和维护性

2、收集并处理设计院的朱珂那边反馈的试用疑问和报错，同时跟朱珂详细讲解说明了Excel的使用与填写细节。排查出他们试用时候图元丢失的情况，主要是目前ELK模块的数据库中对于管理机的类型支持比较少，ELK的布局输出会丢失如ismart8这种新类型的管理机及设备图元；



【2025-06-16-06-20 周工作总结】

- 单机单网功能成功部署上线：解决了环境配置、编码及防火墙等多项问题，将单机单网绘图功能稳定部署至43服务器，并同步上线钉钉工作台应用“CADDrawerAgent”。联系了吴晶晶团队进行初步试用反馈。
- 用户体验优化： 支持Excel录入模板通过下拉框选型及前端校验减少用户输入错误，解决了后端type主动限制的问题；同时编写了详细的用户操作说明文档和项目介绍。
- 推进双网功能实现： 在数据结构层面，完成了对“第二交换机”的支持改造，为双网功能开发奠定了基础；同时，通过用户反馈排查出ELK模块因设备库不全（如不支持ismart8管理机）导致图元丢失的新问题，明确了下一步需协同解决的依赖项。

【本周计划】

1. 协同解决设备库不全问题：将朱珂那边反馈的“ismart8”等新型管理机图元丢失问题进行完善，推动更新设备数据库，以保障真实项目数据的完整性。
2. 推进双机双网功能联调：基于已完成的“第二交换机”数据结构改造，与ELK推进双网功能的联合调试，实现在布局算法中第二交换机的支持。
3. 持续收集用户反馈并迭代优化：主动跟进设计院及其他用户的试用情况，收集更多使用场景下的问题与建议，并快速进行产品迭代与功能优化。
4. 启动意图识别项目的模块研究：识别客户的问题意图，并实现提取关键字作为下游流程的输入

---

工作总结[2025-06-23]

1、更新了完整的通讯层设备的属性库，优先解决了ismart8新类型管理机设备type无法识别导致设备丢失的问题。

2、协助曦哥那边排查并解决了更新数据库后33M坐标偏移的问题

3、解决了cetsoft-svr1账号登录不上的问题，同时排查并解决了代码远程推送过程中因代理导致错误的问题；并更新了推送上去的README文档

工作总结[2025-06-24]

1、详细梳理学习了当前myRoberta的代码库，理解其在项目信息中的处理工作流，以及当前多任务（意图分类、子域分类、实体识别、关系抽取）训练的逻辑

2、差不多理清了王工的Roberta代码整个框架和JSON数据的结构，以及各个分类的配置方法，目前调试遇到点环境问题，需要解决项目中termios与Windows不兼容的问题

工作总结[2025-06-25]

1、解决了ssh连接服务器的问题，初步熟悉了通过Linux完成王工的Roberta预测的项目操作流程

2、调试环境跑通了116服务器上Roberta项目的预测输出，但是发现实体识别的效果似乎还比较差，特别是项目编号经常被拆的很散（Chinese-roberta-wwm-ext和conversation-roberta两个版本模型似乎都这样），然后RobertaV2的导入还有点问题需要修正

3、请教了王工那边，理解清楚了当前最新项目模型RobertaV2的训练情况，以及数据分类的标注含义，后续可以逐步进行发货领域的数据扩充的训练

工作总结[2025-06-26]

1、解决了启动label-studio更新label定义时候出现的django.db.utils.OperationalError报错问题

2、梳理了略哥整理的项目发货问题决策树的问题分类思维导图和之前的项目大类问题汇总，初步根据分类的方向在王工的问答数据集Excel上新增差异性的部分问题集

3、目前根据初步整理的50条通用种子问题集构建了一个GPT扩充样本的prompt模板，后面可以批量生产并进行筛选微调，但是对于打标的实体标签、relation标签这两个难定的，需要后面请教下王工如何扩展且能与之前的规范保持一致

工作总结[2025-06-27]

1、初步整理了一下上半年的工作成果汇总与个人总结

2、整理了问题的分类领域并对种子问题进行了调整和补充。然后同王工确认了扩充方式没啥问题，但是对于问题标签的定义抽象不充分，还需要更新补充一版发货相关的实体与动作的抽象标签，区分实体、属性、动作与意图

3、请教理解了王工的实体建模的人-事-物出发点逻辑，基于此我更新了一些发货领域的实体划分标签。目前三个抽象实体的细部划分比较多，会遇到一些没考虑到的细节实体或属性，同时这也需要更合理的relation抽象设计来表达意图内实体关系，这部分生成数据的时候再去改进。



【2025-06-23-06-27 周工作总结】

- CAD绘图项目支持与收尾： 解决了用户反馈的“ismart8”新类型管理机设备丢失的关键问题，并协助处理了数据库更新后的坐标偏移及服务器部署问题，保障了已上线功能的稳定运行。
- 快速上手新NLP项目（myRoberta）： 深入学习并掌握了myRoberta代码库的整体框架、多任务训练逻辑及数据流，成功在服务器部署和跑通了模型预测流程，完成了项目切换后的技术熟悉与环境上手。
- 启动“项目发货”领域数据扩充与建模： 启动了面向“项目发货”新领域的NLP数据准备工作，包括分析业务问题、构建种子问题集（目前25条种子问题，165条扩充问题），并与王工对齐，初步设计了符合“人-事-物”逻辑的实体标签体系，但是标签的定义我还需要进一步细化和补充。

【本周计划】

1. 核心任务：完成“项目发货”领域首批数据扩充与标注：基于上周确定的实体关系建模逻辑，最终确定实体与关系标签体系，并利用GPT辅助生成扩充问答对，在`label-studio`中完成首批数据的清洗与标注工作。
2. 进行模型增量训练与初步评测：使用标注好的新数据集，对`myRoberta`模型进行增量训练或微调，并初步评测新模型在发货领域的意图分类和实体识别效果。
3. 持续跟进CAD绘图项目用户反馈：保持对CADDrawerAgent用户的支持，及时响应和处理可能出现的新问题。

---

工作总结[2025-06-30]

1、梳理了王工设计的基础属性本体标签与人-事-物的属性值标签的关系，并对目前遇到一些没考虑到的细节实体和属性对其进行了相应发货领域的补充完善

2、通过label-studio对扩展的问题语料进行实体与意图的标记，目前大致75条，边标注边更新label定义

工作总结[2025-07-01]

1、通过label-studio对扩展的问题语料进行实体与意图的标记，目前已标发货领域意图问题语料130条。标记问题的同时更新了关于信息系统等实体标签体系、问题动作判断等动作标签体系

2、目前用已标的75条意图语料以及concat王工之前的预训练语料进行了初步训练，发现对于类似的自创测试问题基本识别还行，但是实体泛化性还是差点，可能目前试训练的实体类型比较集中导致的，这个还需要更多数据来调试训练

工作总结[2025-07-02]

1、目前已标记完新增发货领域的165条扩充数据样本，再加上之前的基础信息共722条训练数据，包括实体、关系和问题意图等标签。

2、新加量版本数据表现在可以实现识别更多实体，包括发货和基础领域。但是对于多实体标签之间的关系却表现的过拟合了，所有实体都强行预测了关系，另外对于意图分类依旧欠拟合，识别准确性不是很高

工作总结[2025-07-03]

1、实验调整了Roberta多分类器中grammar和relation的训练loss权重，另外也尝试了采样降低query意图问题的比例，但是似乎都没啥影响，后面尝试按王工的第二种方法增加数据和数据中对relation的负例标签来训练

2、尝试除了正向关系的标签还给relation增加了none标签，明确告诉Roberta模型"什么是没有关系的实体对"，提供了正负样本的按比例分配的学习方法，缓解"所有实体对都有正向关系"的错误学习模式。但是grammar预测效果依旧需要改进

工作总结[2025-07-04]

1、尝试了使用多阶段训练的方法，针对不同难度的多分类问题分别进行训练，一阶段专注于基础任务（实体边界 + 语法分类）。阶段2再引入实体类型分类，识别文本词条所属实体标签定义。阶段3最终再全面学习关系抽取，正负样例关系都训练学习。但是目前实验效果并不明显，需要调整权重超参数或者整理数据质量和数量

2、调整了自动绘图的模板图元中文字展示定位异常的问题；另外配合陈燕燕那边完成外网版CET智译上线钉钉。

3、对标注的relation数据做了清洗，修正所有unknown的relation标注，统一为none的负例标注。进一步进行训练调试实验



【2025-06-30-07-04 周工作总结】

- 完成发货领域首轮数据标注与模型训练： 完成了“项目发货”领域首批165条扩展语料的实体、关系及意图的语料标注，并结合存量数据（共722条）进行了多轮模型训练与AB测试评估，并记录了对比测试结果
- 定位到模型关键问题（过拟合/欠拟合）： 通过训练定位了“关系抽取”存在过拟合、“意图分类”存在欠拟合的核心问题。通过引入“无关系”负例样本的核心训练方法，对关系过拟合问题有了初步缓解。但是对于高难度的意图分类依旧不准确，目前已实验了调整损失权重、多阶段训练等方法策略
- 解决跨项目支持问题： 标注数据训练模型的同时，继续为CAD自动绘图项目提供技术支持（修正图元文字定位）并回应朱珂那边的绘图问题，以及协助完成了“CET智译”的外网版上线工作。

【本周计划】

1. 核心任务：系统性提升意图分类准确率：针对当前意图分类欠拟合问题，计划通过扩充意图多样性的训练样本、构建单独针对意图的分类器模型结构、调整损失函数等方法优化训练实验。
2. 精细化数据与调优实验：利用大模型来清洗和优化现有标注数据，确保标签一致性；并系统性地调整超参数（如学习率、权重），对上周尝试的多阶段训练、负例采样等方法进行更深入的调试。另外对训练损失进行可视化的实现。
3. 持续扩充高质量训练数据：根据评测结果，分析模型薄弱环节，有针对性地设计和生产新的高质量训练数据，尤其是当前覆盖不足的实体和意图类型。



----

工作总结[2025-07-07]

1、回应设计院朱珂那边绘图的问题与需求，如缺少柜号导致接线不显示和图框选择等问题，以及要把项目属性值自动填充到图框中等需求

2、实现了基于王工Roberta代码的训练loss趋势的可视化，目前针对实体边界、实体类型分类、关系与语法抽取分别进行了训练效果的分析，初步得出Roberta改造的多分类器在不同任务上的表现

3、在使用RoBERTa进行多类别分类时，无论采用何种训练方法和参数调整，“语法”类别的分类性能都很差。按王工建议我尝试尝试在不改变Roberta的多分类器输出层的情况下，调整分类器训练权重，只保留grammar的训练梯度，使用的concat的700+的标注和学习率等配置。但是效果不理想，其他三个类无法识别是在意料之中，但是grammar训练了依旧无法识别就一定程度说明多分类器结构对这个难度的问题不是很实用

工作总结[2025-07-08]

1、梳理理清了Roberta训练可视化图中关于loss训练竖线的问题，主要是step在训练中与参数更新频率不一致的原因。但是loss图的整体趋势还是说明了entity-type的过拟合。

2、解决了朱珂反馈的图框属性值（如项目、内容、图号等）硬编码的问题，调整原始cad_schema信息以正确应用总览中的信息，实现了按要求自动完成填充。

3、排查解决了绘图中设备层图元显示不出设备名称的问题并告知了朱珂那边。

工作总结[2025-07-09]

1、梳理了王工之前设计的Roberta多分类器网络的架构，同王工讨论了关于如何修改数据结构label与模型的输出层的问题，确定先通过简单数据来训练Roberta实验其对grammar的拟合效果

2、结合原始创建一个专门用于语法分类的二分类或单任务分类器。并整理建新的数据集文件，用于特定于grammar的训练。目前已经改了一版Roberta只针对grammar的网络训练结构，但是tensor对齐还有点问题需要调整

工作总结[2025-07-10]

1、搭建并完整实验了只针对grammar语义识别问题的单独输出层Roberta的训练模型，实验了调整不同超参数与label权重比例的情况，但是结果初步都基本显示无法泛化学习到真实grammar语义。同王工讨论了后续从数据简化上去改进，先实验一下简化为3类易区分label的grammar进行训练

2、完成中国电子系统的工程系列职称申报和系统填写

3、修改了grammar的标签类数同时调试修改了训练的输出神经元个数与类数对应，但是调通后发现预测标签经常出现预测错乱的情况，这里需要实验排查看一下底下设计的编码是否准确对上了

工作总结[2025-07-11]

1、目前发现当前测试效果不好的原因不全出在数据集质量上，模型计算的F1分数好但训练集测试还不好这个是矛盾的。和王工讨论后解决思路主要分两个去实验排查，精选50个容易分辨的grammar的优质数据集；另外尝试把grammar多分类问题移到subdomain分类器上，这个subdomains单分类器是更简单、易处理

2、清洗训练数据集，去除历史数据中存在的少量错标以及可能有歧义的标注数据。同时继续调试排查多分类编码错误的原因

3、排查出主要是编码对齐的问题，目前已实验解决了在grammar单分类的Roberta上训练准确性的问题



【2025-07-07-07-11 周工作总结】

- NLP语法识别难题攻关取得突破性进展： 针对“语法”类别识别率低的问题，通过构建独立的单任务分类模型、简化标签体系等一系列实验，最终定位并修复了“标签编码错位”的底层BUG，成功解决了grammar语法模型的训练准确性问题。但是目前混合多分类器的协调训练的稳定性还需要实验提升
- CAD绘图项目功能迭代与用户支持： 响应设计院朱珂反馈，完成了图框项目属性值的自动填充功能开发，并修复了因缺少柜号导致接线不显示、设备名称不显示等多项问题，提升了应用的实用性。
- 模型训练分析工具与方法优化： 实现了训练过程损失（loss）的可视化，为分析模型在多任务上的过拟合等表现提供了直观依据；尝试多任务的多轮训练策略（调整权重、单任务输出、简化label等），但效果目前仍有限。并通过与王工的深入探讨，明确了后续模型优化的多种策略。

【本周计划】

1. 核心任务：探索语法分类任务的最优集成方案：研究将已验证有效的语法单任务分类器，重新整合回主多任务模型中的可行方案；或作为备选，尝试将语法分类任务迁移至结构更简单的`subdomain`分类器上进行实验，对比效果。
2. 聚焦多任务分类优化：继续验证多任务分类器在不同数据分布与标签设置下的效果，探索label简化与数据增强的组合策略。
3. 提升整体模型综合性能：在语法问题取得进展后，重新审视并优化实体（entity-type）过拟合等其他遗留问题，通过数据增强、调整模型结构等方法，提升模型的综合表现。

---

工作总结[2025-07-14]

1、已实验解决了更新grammar模型后，多任务分类中entity识别异常的问题，主要还是编码对齐和之前调试的权重没更新的问题

2、参加入职一周年职业导师线下会议的谈话

3、测试来看目前多任务分类grammar和entity问题不大，主要是subdomains和relation预测不准，他们的数据都比较差、另外relation分类预测任务相较另外几个任务难一点

工作总结[2025-07-15]

1、实现优化当前训练代码流程中模型保存和模型命名的功能，避免每次调试训练模型被覆盖的问题

2、调试解决了subdomains分类任务中forward编码没有进行转换的问题，修改preprocess的编码减一来对齐任务的loss计算过程。目前subdomains和grammar的识别提取基本都能准确

工作总结[2025-07-16]

1、上午完善之前的职称申报的材料；另外补充绩效评估的材料

2、目前Roberta主要是在entity和relation的识别与提取上准确率不够高，所以针对训练过程，下午研究了一下如何结合贝叶斯优化来调整当前的分类器权重与训练配置的超参数组合

3、另外针对训练的数据集，下午把构造的测试数据集中预测效果有问题的做了梳理汇总，针对这些badcase继续专门的数据增强，目前现扩充一批这些badcase数据集

工作总结[2025-07-17]

1、针对之前测试收集整理的预测badcase样本数据，将其作为种子问题进一步扩充了这部分训练语料的比例，目前新增55条badcase上相近的数据样本

2、跑通了利用随机搜索和网格搜索的超参数优化的方法，为了小步实验验证，针对仅训练的training_arg进行15组参数组合搜索训练，结果效果挺好，在之前的大部分badcase上也能够准确预测出来，badcase上仅少部分entity预测还是缺失，后续可以进一步使用贝叶斯优化算法，并结合接下来计划补充进来的基于badcase扩充数据来增强训练，大概率会有好的效果

工作总结[2025-07-18]

1、进一步实验通了随机搜索算法针对Roberta模型的训练配置+多任务权重的组合优化，新超参数组合在原有badcase数据集有进一步的改进，原始预测会丢失的entity能够准确召回

2、实验普查了代码在训练上是否有错误的地方。排查后发现的异常信息是，验证集的entity与relation的F1值很低，怀疑可能是数据稳定性方面的错误或者数据比例失衡导致的。目前初步实验研究了一下metric计算上的设计，但还没找出问题原因

3、另外同步针对之前测试收集的badcase进行扩充数据的标注，这部分又增标了30+的语料样本



【上周工作总结 2025.07.14-07.18】

- 修复关键BUG: 解决了`subdomains`分类器的编码对齐、训练结果保存与可视化等问题，模型四大任务中的（grammar、subdomains）任务得分能到90+，基本可用；但entity和relation 识别仍是薄弱点，已开始聚焦优化。
- 引入自动调优: 应用随机/网格搜索找到更优超参数组合，之前预测失败的“badcase”目前大部分已能被模型准确识别。
- 精准增强数据: 针对模型弱点，定向扩充了80+条与“badcase”相似的高价值语料。

【本周计划】

1. 解决F1值异常: 彻查验证集entity/relation F1值过低原因，分析数据分布与评测代码，必须确保评估体系可信。
2. 应用新数据与贝叶斯优化: 完成80+条标注数据并投入训练，并引入更高效的贝叶斯优化算法，继续攻克疑难样本。
3. 实验解决“关系与实体抽取”: 集中精力解决（entity、relation识别任务），尝试针对性数据增强与Lora方式训练模型。

---

工作总结[2025-07-21]

1、遇到并解决了模型加载错误的问题，排查后发现是因为修改扩充了label范围导致原有模型输出size对应不上

2、实验调试entity与relation的验证集F1值极低的问题，打印输出了很多之间loss已经混淆矩阵，但这块目前还没有明确的发现，预测根本原因还是任务难度不均衡导致这两个任务学习失败

工作总结[2025-07-22]

1、排查解决随机搜索算法更新的训练配置参数设置前后不一致的代码问题，解决无法还原之前模型训练效果的问题

2、梳理当前模型多个任务的输出头（线性层）的设计，初步调研研究多不同难度任务的分离训练方法

工作总结[2025-07-23]

1、排查并解决了116的容器上网络默认代理对api服务的影响，避免了容器劫持测试开发的api请求的问题

2、实现把之前训练的当前中间效果最佳的模型做成api的形式，方便后续快速验证效果并迭代。目前在修复导入复用 `my_roberta_conversation` 类方法中出现的bug问题

工作总结[2025-07-24]

1、基本解决并实现了当前已训练的多任务Roberta模型在服务器容器中api接口服务，后续可以对接项目助理的决策树的实体名词来进行对齐和预测测试

2、实验跑通了冻结参数的分离式Roberta训练策略，解决了期间碰到的很多如batched张量不匹配、实例方法调用不正确等等问题，目前我主要是分冻结entity和relation参数的阶段一与冻结grammar和subdomain参数的阶段二来尝试进行优化训练。这条路线的预测效果还需要进一步实验测试

工作总结[2025-07-25]

1、实验了训练超参数优化的目标从combined_f1更换为evalLOSS，以减轻entity和relation任务极低F1值对优化配置训练的影响，实验下来发现确实优化的超参数组合确实能够出更完美的loss曲线，但是entity与relation测试效果却降低了，预测是新优化目标让模型学会了避重就轻，偏向训grammar和subdomains的简单evalLOSS

2、对接雷鹏那边了解了问答领域的数据情况，他这块目前基本都是脏数据LLM都不好分辨，还需要等他那边问题决策树的节点名词出来再对齐Roberta的实体标签。关于早期阶段的Roberta模型的API接口我已经开放给雷鹏去试用了

3、下午把最近标注好的badcase的补充数据集50个样本补充进去，实验发现针对badcase的问题是可以通过不断补充垂域相关的泛化数据进行有效改善的



【2025.07.21-07.25 周工作总结】

- 初始模型已封装为API服务： 成功将之前的阶段训练最优Roberta模型封装为API接口，已开放给R组用于对接项目助理的决策树，并明确后续需基于“决策树节点”进一步优化实体标签体系与效果验证。
- 模型训练与优化调整
  - 解决因 label 扩充导致模型加载异常的问题；修复了训练配置不一致导致随机搜索效果复现失败的问题。
  - 实验了冻结参数的分离式训练策略（entity/relation 阶段一，grammar/subdomain 阶段二），成功跑通训练实验流程。目前观察发现loss曲线很好，但是意外的是entity部分样本会丢失。说明后续需单独去训练entity/relation
- 验证数据策略有效性： 
  - 实验证明，新增 50 条 badcase 补充语料，实验证实对薄弱预测样本具有提升效果。同时，也验证了单纯优化loss会导致模型“避重就轻”，忽略`entity/relation`任务。

【本周计划】

1. 解决entity/relation任务F1低的问题： 实验entity/relation单独训练模型的策略，评估是否能平衡难度差异。通过调整训练顺序与超参数，找到提升`entity/relation`任务性能的最优组合。
2. 持续精准增强数据： 根据分阶段训练和API批量测试中发现的新badcase，继续定向扩充增强训练语料，特别是针对`entity`抽取任务的复杂样本，构建“问题预测-数据失败回流-模型增强”的闭环优化流程。

---

工作总结[2025-07-28]

1、基于之前实验的冻结神经元训练效果不佳的基础上，尝试另外一条路线-实现拆解4任务训练器为entity和relation的双任务训练器

2、目前已经解决了针对双任务的网络架构、数据处理以及labelMAP对齐的等等诸多bug问题，第一次实验下来发现，相较于之前冻结四任务部分输出神经元权重的效果模糊的实验，单独抽离出两任务的Roberta模型是确定的可以提升模型在抽取entity上的稳定性，减少entity_positions之间交叉的错误问题出现

工作总结[2025-07-29]

1、排查解决了entity/relation的loss计算与labelmap双任务对齐问题，基本跑通了单独针对双任务模式下的Roberta训练与推理，手动测试下来，分离后的双任务效果是要好于四任务的输出的对应位置

2、尝试同步的把grammar/subdomains双任务也抽离出来，这里还有点bug，grammar/subdomains是基于cls语义向量计算metric的，需要适应l不同的oss调试方法

工作总结[2025-07-30]

1、基本跑通实现了两个双任务的Roberta模型的训练与推理过程，解决了grammar/subdomains基于cls语义向量的loss配置问题。

2、同时我实现了把两个双任务的预测输出进行拼接，实测下来拼接结果效果是有改进的，entity命中概率有较大提升。所以基于此我已经把意图识别小模型的API端口更新到8000/api/v2/predict的两双任务的推理输出版本

3、调研学习当前语义识别任务上的强化学习技术路线

工作总结[2025-07-31]

1、排查解决了导致`span_f1`和`relation_f1`分数极低的根本原因，数据预处理与评估不一致。在预处理阶段`span_entity_labels`被保存为列表格式，但在`compute_metrics`中，代码期望的是张量格式来提取第三列（标签ID），导致，代码始终创建了全零的虚拟标签。目前已经将预处理的列表与metric的张量统一分开处理。

2、实验并学习PPO方法的路线，目前实践是初步简化奖励模型为原始两个加权的F1、以及新加position重叠负奖励。但是目前看来RL框架还是比较复杂难理解，还需要和AI进一步协作来试验搭建

工作总结[2025-08-01]

1、排查解决了库的版本环境的报错问题，解决了更新强化学习库同步改变了之前的sft的包，导致一些推理时候forward函数不兼容的报错

2、试验并理解DPO与PPO在文本处理上的实验示例代码。自己在初步实验DPO的偏好数据的微调方法，但是依旧回到了数据处理上，目前准备通过基于实体位置+F1分数对比来筛选badcase用于构造新的偏好数据，但是还是有模型预测结果莫名其妙的问题以及一些实现上的bug需要解决



【2025.07.28–08.01 周工作总结】

- 多任务模型结构重构优化: 成功将原四任务模型拆分为两个独立的双任务模型（entity/relation 和 grammar/subdomain），发现entity识别稳定性显著提升，同时更新了/v2 API接口。另外分离任务的模型也是为方便针对性DPO强化学习实验
- 指标异常定位与修复: 成功定位 span_f1 和 relation_f1 长期极低的根因，修复了预处理与 metric 不一致导致的全零标签问题。方便后续将F1作为奖励的一部分。
- 强化学习路线探索: 已启动基于强化学习（PPO/DPO）的优化路线探索，并初步完成了对DPO偏好数据构造方法（F1加权+位置重叠惩罚）的实验。当前主要问题集中在偏好数据构造逻辑与部分 bug 调试。

【本周计划】

1. 继续完善 RL 微调流程：从技术探索转向具体实施，重点构建用于DPO的偏好数据集（筛选好/坏预测对），并进行首次模型微调实验。
2. 研究PPO/GRPO的奖励模型搭建与训练的实现方法，尝试进一步利用构造的偏好对来训练专门的Reward Model

---

工作总结[2025-08-04]

1、排查出构造偏好对样本时基线模型预测输出质量极差的原因是因为库的函数功能不一致，在huggingface的transform库中模型配置加载的` from_pretrained`方法与BertConfig.from_pretrained在加载基线模型权重上不同，这就导致预测输出老是与预想的不一致，目前已排查并解决

2、另外在DPO强化学习的偏好三元组数据集构建中还遇到基于规则与F1分数来筛选原始数据集比例异常的问题，我之前实测是存在个别的实体预测不准或丢失的badcase，但是目前筛选逻辑却统计显示大部分都是高F1预测，这也与预期的比例对不上，目前问题还在进一步微调修复中

工作总结[2025-08-05]

1、实验通了利用固定规则与样本F1分数作为简单奖励模型的方法，但是目前测试出来的输出不符合预期。基于F1分数与整体平均分数对比的方法会把绝大部分样本判为高质量样本（异常猜测是由于单样本实体数较少的原因），而基于规则（实体重复、实体位置重叠、空结果）的方法的负奖励计算涉及的样本比较少。后续应该先试着优化F1值的判定

2、参加AI小组周例会；完成总结2025上半年绩效评估责任书

工作总结[2025-08-06]

1、基本跑通了基于多规则筛选与F1分数评估的DPO三元组数据集生成，能够把所有badcase返回给我并构造多样性的chosen-rejected pair样本数据集。这是在已有数据集下的意图识别模型迭代优化的数据闭环基础

2、梳理当前迭代的记录内容，方便与王工讨论强化学习的研究现状，并整理之前意图识别模型API接口文档以及数据集和lable抽象化解释的文档，初步给周晖说明当前意图识别的结构与现状

工作总结[2025-08-07]

1、排查并解决了构造生成的偏好对数据集JSON中relation的结果缺失以及idx重复的问题

2、整理最近跑通的SFT训练和构建的RL偏好数据集的阶段记录内容，同王工讨论现状和具体效果以及后续规划。重点设计评估的侧重点与边界情况，然和协同AI来填充具体的评估方法，暂不考虑扩大识别的范围

工作总结[2025-08-08]

1、调研整理意图识别的评估方案，协同AI来设计具体的评估指标，设计评估数据集的构造，目前最缺的还是数据集

2、整理之前的训练数据集频率情况，以及问题的类型分布，目前初步整理了测试评估数据集的生成方案，以及一部分待标注数据



【2025.08.04–08.08 周工作总结】

- 偏好数据生成闭环: 成功实现基于多规则（实体重复、位置重叠、空结果）与F1分数的badcase自动筛选，现可稳定生成DPO所需的偏好对（chosen/rejected）的新数据集。
- 关键BUG修复: 解决了因模型加载权重方式不一致导致的基线预测错误，以及生成偏好数据JSON中relation 缺失、样本 idx 重复等数据一致性问题，为DPO流程以及模型评估的设计扫清了障碍。
- 评估方法与测试集设计: 已完成意图识别模型的评估方案设计，并完成了初步评估数据集构造的思路与部分待标注的测试样本。

【本周计划】

1. 构建并标注评估数据集： 完成首批标准评估数据集的标注工作，为量化模型性能提供可靠基准。
2. 量化DPO微调效果： 在上周生成的偏好数据集中进行首轮DPO训练，并在新评估集上，对比RL微调前后的模型性能，用数据验证DPO策略的实际提升。

---

工作总结[2025-08-11]

1、参考之前的变种问题筛选构建了33个评估样本的数据集，并在label studio上完成新的评估样本的完整标注

2、构建了初步的基于F1分数的基础评估脚本，进行分数计算，发现grammar、subdomains的f1都非常接近1，然后entityf1在0.7这样。

3、我从数据集上详细对比发现根本问题主要是在数据集的质量上和评估方法设计上，首先label体系边界划分还是不够完善，然后我前后标注的时候也会存在少量不一致情况；其次，目前entity测试效果主观看还行，但是F1作为评估指标是字符级别的，计算分数比较苛刻，所以分数虚低。还需要进一步研究合适的处理办法

工作总结[2025-08-12]

1、实验在评估数据集的一致性标注中引入AI打标，实验了结合钉钉多维表格的AI功能，写好包含label框架的初步提示词来批量对表格数据进行多任务拆解的打标。初步结果发现grammar、subdomains确实可以很快很稳定的生成标注，但是到entity上相较于我自己标注AI很容易缺省部分实体，相当于AI的精确率高但是召回率低

2、梳理并优化了评估结果对比的可视化方法与脚本，目前能够更直观的找出评估测试结果中badcase到底是预测的问题还是标注本身的问题，基于此就可以进行数据的迭代优化

工作总结[2025-08-13]

1、排查评估结果relation分数低的问题。从可视化发现除了entity中的一些label标注歧义问题导致relation不匹配外，还有relation的评估集中缺少负关系，这部分写好修复函数后f1效果有少量提升

2、继续深入数据集层，通过评估对比结果发掘标注中不合理的以及错误的label体系，修复比如panel和box容易混淆标错的标签等等。然后梳理略哥那边的多个表结构的实体，目前正在把这些正在用的新实体都融入到label体系中

工作总结[2025-08-14]

1、完整的把略哥那边的外部多个表结构中的所有实体全部融合到当前entity实体框架体系中，同时也完整重构了旧版的标签JSON，从 "my_roberta_entity_labels.json" （82个实体）修改为 "entity_labels_v2_final.json"（184个实体），实体范围更全面且分级分离的更清晰，彻底解决之前标注体系存在少量混乱和歧义的问题

2、目前已经部分实现针对重构的entity标签标注数据转换到新新框架下的标注数据，比如1to1和Nto1标注目前已经通过函数的方式转换新版本标注，还需要针对1toN的样本进行单独处理（原始仅7类一级抽象实体） 转换为新entity框架（18类一级实体）。后续新的label必定更具兼容性能，同时也减少标注的混淆性。

工作总结[2025-08-15]

1、针对昨天重构的新的entity标签框架进行原始标注的映射优化修改，处理脚本无法自动匹配的1toN标注分配的转换问题，目前已经完整的把原始标注转换为新184个实体框架下的数据集

2、针对标签数据集完成了映射的校验和人工检查，最大程度确保数据集中不再有歧义的标注情况，目前可以用新数据集训练Roberta的意图识别模型，实验了一下，可以在略哥的外部表结构实体数据上构建问题进行一部分的意图分类（因为原有语料包含部分表结构中的新实体数据）

【2025.08.11–08.15 周工作总结】

- 重构并扩展核心实体标签体系： 完成实体标签体系重构，解决评测中发现的标注混淆，同时全面融入外部表结构中的业务实体，实体数量从82个扩展至186个，大幅提升体系的清晰度与覆盖度
- 完成配套数据迁移与测试验证： 设计方法将全部旧标注数据自动映射至186的新标签体系下，并完成了人工校验。初步训练验证，新训练模型也能识别大部分新业务实体，可以提供接口接入试用
- 评估体系构建并引入AI辅助： 构建并标注了 33 个新评估样本，实现基础 F1 评估和可视化脚本；发现 entity F1 ≈0.7，grammar/subdomains F1≈1。并实验了引入AI来辅助标注，但是效果一般。

【本周计划】

1. 按需扩充新实体相关语料： 分析新模型在新实体上的识别短板，定向补充相关问答语料，快速提升模型对新业务的覆盖度。

2. 优化评估指标与模型续训练： 使用迁移和校验后的186实体新数据集，训练新版意图识别模型，并在评估集上进行评测，同时优化评估方法以避免字符级F1带来的分数虚低问题。

---



工作总结[2025-08-18]

1、实验修改偏好数据集为transformer的TRL框架下的数据格式，但是目前遇到dpo训练的难点，使用trl框架需要添加包装器将多任务输出的模型头转换为生成模型的CausalLM格式

2、尝试简化之前构建的新的entity标签框架，设计并优化其中部分过于细化的实体名称。另外同步的修改部分标注数据的映射逻辑

3、整理了意图识别的模型评估、框架拓展的应用、dpo训练实验的现状以及问题，和王工确认了以标注数据优化和新实体语料补充的核心研究优化路径，后续会进一步筛查原始数据和标注中问题样本和测试的badcase，用来进一步迭代优化

工作总结[2025-08-19]

1、整理原始标注JSON数据集的时候发现之前扩展的标签新框架有点冗余，手动处理1toN的原始映射转换的时候不是很好打标，所以我重新简化了一版本标签文件到entity_labels_v3_final.json的第三版，从之前的v2版本186个实体简化提炼到v3版本146个实体，既保证领域实体覆盖，也确保打标减少标签重叠的歧义

2、重新调整Roberta模型的标签和新框架训练后的模型配置，同时也将API更新到最新兼容的新框架模型，方便模型接口能同步的支持略哥那边的新表结构实体数据，实现后续数据及模型的双迭代优化

工作总结[2025-08-20]

1、整理完成意图识别小模型的接口集成代码，通过装饰器的方式成功嵌入A组的问答工作流中了，目前可同时返回Roberta和LLM的意图识别结果，方便后续数据和模型迭代

2、调研了R组的问答工作流情况，R组是先对用户问题进行三分类（chat闲聊、download文档查看、query信息咨询），再考虑回答，且会拼接约多条历史记录辅助识别意图。所有可以先仅尝试支持对query的小模型训练以替代这部分的大模型回答。而R组的槽位比较复杂不固定，依赖大模型根据大致信息做决策，所以这部分先不做替代的模型训练

工作总结[2025-08-21]

1、为了解决实体匹配的评估中采用集合等价即“完全一致才算TP”，否则要么是FP（多报）要么是FN（漏报）的局限性问题，新增了Partial-IoU（实体重叠率大于0.5都算tp=1） 和 Semantic（实体有包含关系算tp=0.8，全等算1） 包含两个补充评估指标，可以避免因为严格匹配的f1而压低指标

2、对A组以及R组的测试数据进行整理并结合GPT生成部分变体语料。目前标注了一小部分样本，同时实验利用AI表格的方式也实验了自动预标注一部分减轻标注工作量

工作总结[2025-08-22]

1、排查并修复了新的IOU宽松评估方法中，会把所有评估TP的统计都视为子串识别的问题进行处理了，目前可以正常实现对A组提供的测试集问题进行合理的近语义级别的宽松匹配评估，F1值从之前压低的0.69提升到更加合理的0.76，说明绝大部分样本都能很好的进行意图识别与槽位提取

2、继续进行一部分A组训练样本的label studio的手动标注，同时结合多维表格的AI功能结合新label框架进行微调提示词逐步实现更加精准的自动标注，避免当前AI标注容易出现错误的entity_idx位置值。目前自动标注以可以部分拿来作为人工标注的补充和参考

【2025.08.18–08.22 周工作总结】

- 模型集成上线： 意图识别模型已通过API成功嵌入A组的问答工作流，现与LLM并行运行，为后续对比优化和数据迭代提供了实战环境。
- 评估体系升级： 针对字符级F1评估过于严苛导致分数虚低的问题，新增了Partial-IoU等更合理的近义匹配评估指标，使A组测试集F1分数从0.69提升至更真实的0.76。
- 数据框架最终定版： 为提升标注效率与准确性，将实体标签体系从186个精简至146个（v3版），并完成了模型与API的同步更新，已能支持部分新业务实体的预测。

【本周计划】

1. 数据生成与标注：扩充 A 组样本标注，结合多维表格进行预标注，针对R组工作流，生成并标注首批仅“query”分类的小型数据集；
2. 应用新评估体系定位badcase： 利用上周升级的评估脚本，定位在新业务实体与复杂意图上的识别短板，进行样本的补充与增强

---

工作总结[2025-08-25]

1、排查并解决了新JSON数据验证的函数报错问题，通过函数修正AI部分不稳定的异常标注，如Contract_Baseinfo -> Contract_Info、Action_Changed -> Action_Updated等等

2、完整的A组新框架的495个样本数据我都加入训练了，应该是确保了小模型上线使用的准确性和稳定性。（这块主要是已经实验通了自动化标注 通过多维表格AI和脚本修正与验证的方式完成）

工作总结[2025-08-26]

1、为Roberta小模型添加功能实现了非极大值抑制(NMS)机制，用于解决badcase中发现的实体边界重叠的问题。在实体预测循环中添加置信度计算，添加IoU计算函数，添加NMS函数，在推理流程中应用NMS，例如如果IoU超过阈值(0.5)，则抑制(移除)那些重叠的实体

2、通过LLM生成的方法，为测试数据添加了更多覆盖各种实体类型的代表性测试语句，确保测试集能够说明模型对大部分实体类型都有预测的泛化能力

3、调研整理王工规划的基于A组工作流过程的评估方案，从输入合规、意图识别槽位提取、sql生成、答案生成 这四个完整节点来分别构造整理测试评估方法

工作总结[2025-08-27]

1、调研整理sqlAgent评估的方案，并在AI小组例会上确定后续的评估方向

2、初步设计了一版MongoDB Agent 质量评估框架，针对比较清楚的输入语料层构建了比较清楚的语料扩充的结构方案、以及第二层语句抽取和意图识别基于我之前完善的意图识别方法也设计了更全面的评估指标。然后是sql生成和最终答案生成这两个不好确定黄金标准的评估层，主要从准确这个目标的侧面来设计规则性的自动化审查，在结合部分的人工主观筛选，来完成初步完整的流程评估。

工作总结[2025-08-28]

1、继续调研并完善针对MQLAgent的评估方案框架，特别是L3、L4两部分设计更加清楚的规则性检测评估以替换需要黄金标准的评估

2、初步详细整理了一下在L1层的评估数据构造需要的类别和意图子类的划分，当前独立的分为典型问题验证Agent能否正确处理定义明确的、可直接回答的各类查询（比如“查询项目负责人”、“统计项目数量”、“查询发货状态”等），包括能返回数据和返回“空/边缘”结果的情况。以及其他苛刻条件下Agent的稳定性测试评估问题，实体密集型问题、歧义问题、领域外问题和无效/恶意问题的类别分类

工作总结[2025-08-29]

1、利用初步整理的评估样本数据进行项目助理Agent的测试实验，目前发现Agent对于无效和恶意问题的抵抗拒答效果是蛮好的，但是对设计的歧义问题需要的澄清效果略微差点。

2、设计整理了一下针对L1三个量化指标的计算方法，通过对分类评估样本的预测效果的比例来说明输入层的合规性与鲁棒性

3、初步修改了评估方案的文档和王工讨论了一下，当前大体框架基本就是这样了，然后内部评估的分指标的细节还需要与A组对齐讨论

【2025.08.25–08.29 周工作总结】

- 调研评估框架设计： 设计了一套覆盖“语料输入-意图识别-MQL生成-答案生成”四层级的完整评估框架，并已开展初步测试，验证了Agent在拒答无效问题上的有效性。
- 模型训练与优化： 基于自动化标注，完成了A组全部495个样本的训练；并引入非极大值抑制（NMS）机制，解决了实体边界重叠的badcase。
- 评估数据构建： 详细设计了L1层评估数据的分类体系，覆盖典型查询、实体密集、歧义、领域外及无效/恶意问题五大类，为后续量化评估奠定基础。

【本周计划】

1. 研究检索A组各环节数据： 研究从laminar框架数据库建立提取所需任务数据的管道，根据数据情况同步并敲定评估框架的各项指标与细节，确保评估维度符合项目组需求。
2. 尝试优先跑通前两层评估实验： 利用新数据集对助理Agent进行语料输入、意图识别两个环节任务的初步评估，量化其在各任务子维度下的性能，明确后续优化方向。

----

工作总结[2025-09-01]

1、研究整理了一下laminar框架的使用方法，数据获取都在clickhouse库，目前先本地提取数据构建评估计算方法，后续就可将评估函数转移到laminar原生的自动化评估框架中

2、初步实践了一下结合dbeaver提取的数据进行单一追踪对话trace的探索性分析，针对每个trace分析当前划分的四层任务目标数据的字段情况，理清需要的目标字段如何抽取，目前这块还在进一步调试梳理

工作总结[2025-09-02]

1、进一步梳理针对单一追踪对话trace的探索性分析，从中筛选我们在L1层语料合规性评估所需要的文本内容，这里需要设计一些关键字段的匹配进行计算是否与黄金标准一致

2、初步设计了一些提取的脚本并尝试计算匹配的比例，但是目前在评估对象的提取精准定位上还遇到些难点，以及如何加入我之前分类好的语料的黄金标准也需要考虑一下嵌入的方法

工作总结[2025-09-03]

1、初步实验了问题语料的黄金标准与助理Agent匹配计算评估的方法，这里是修复了之前AI自己生成的基于关键词的语料分类评估的方法，之前评估对象有误。现在是基于我自己标注的语料分类来进行匹配计算f1值。但是目前有点问题就是对A组历史已输入数据的标注需要利用标注处理一下

2、L1层评估的管线初步理清并搭建了一版，但是目前还有部分处理上的bug需要针对性调试一下

工作总结[2025-09-04]

1、排查并修复了从laminar的数据库中抓取同一trace下对话数据错误以及抓取数据过时的问题，目前已经完整实现了从数据库中提取历史问题进行打标得到gold_category，这里结合了钉钉AI多维表格的方式快速自动化打标

2、也跑通实现了从助理Agent的中间环节回答中提取subAgent的最终决策。也就是当有明确接受或拒绝"valid"字段以字段为准，没有明确结果的subAgent则以"抱歉", "无法处理", "不能回答", "请提供更多信息",等等类似文本去匹配获取Agent对于输入语料的L1层决策结果，这部分细节后续再决定继续深入优化

工作总结[2025-09-05]

1、解决了之前从laminar数据库中匹配trace总是出错的问题，主要是API是没有trace_Id的，通过时间戳检索laminar的clickhouse数据库会出现UTC的时差错配问题

2、完整解决了在线评估的问题。原始项目助理Agent的API只能返回最终回答结果，现在实现了通过在线API接口参数匹配clickhouse中间环节数据库的方法获取中间数据的特定spans进行有针对性的完整评估

3、目前可以通过标注数据集批量在线请求完后进行完整的F1指标的计算。实现跑通了在线评估管线，包含批量API异步请求、trace等待、匹配查找，以及将评估数据集黄金标准与agent_behavior进行匹配评估计算。目前还剩部分评估细节待优化

【2025.09.01–09.05 周工作总结】

- 在线评估管线跑通： 成功打通了从批量API请求、匹配Clickhouse数据库trace、提取subAgent决策 到计算F1指标的L1层的在线评估全流程，解决了API缺少trace_id、UTC时差错配等关键数据处理难题。
- 评估数据与方法建立： 利用钉钉AI表格完成对历史输入数据的自动化标注然后人工抽查的方法实现了评估数据生成管线。并建立了基于“标注黄金标准”与Agent实际决策进行匹配计算的评估方法。目前20构造样本的L1层初步评估中TP 9、TN 1、FP 9，准确率: 52.6%、召回率: 100.0%（仅作参考）

【本周计划】

- 优化L1层完整评估： 目前初步评估管线（标注数据 - 批量预测 - 匹配评估）基本完整了，接下来调优语料分类以及匹配算法代码调试，确保黄金标准引入更精准，量化当前Agent的鲁棒性。
- 设计L2层黄金标准数据并进行评估： 在L1数据生成与管理的基础上，开始设计L2（LLM意图识别）的评估方法与评测集，不过这里要重点研究LLM实体系统的黄金标准label的构建。

---

工作总结[2025-09-08]

1、目前整个L1层评估的计算管线跑通了，但是计算设计的代码还有点bug（subAgent的计算优先级存在混淆），这部分还需要进一步调试

2、梳理了L1层评估的现状，目前实现clickhouse的成功解析，匹配对应trace_id的subAgent评估对象，也就是目前有了y_true，也能批量预测并获取到y_pred。但是对于指代subAgent的评估效果一般，这部分和王工以及略哥讨论后决定当前作为非重点指标评估，所以构造评估集数据会微调一下大致分布，以及自动标注的设置

工作总结[2025-09-09]

1、解决L1层评估中subAgent结果的优先级解析错误的问题。排查并调试之前代码中对于指代消解子Agent的输出结果总是被语义校验子Agent的结果覆盖的代码设计问题，同时也把这两个subAgent的评估指标进行区分，避免混淆

2、优化多subAgent评估结果报告生成的输出结果，调试日志的代码，这部分目前实现了通过表格的方式进行对比输出展示，这样同时也能导入到之前自动标注的多维表格进行对比观察

工作总结[2025-09-10]

1、优化代码。对L1层评估的报告生成代码做了进一步优化，现在可以直接查看问题是具体到哪个badcase，然后对应的subAgent是怎么样的输出，这样可以更加方便进行后续的提示词或者Agent迭代

2、深入调研审查了之前对于L3层评估的方案设计。在与GPT多次讨论和分析过后，将其原始的层次二和层次三的关键结果数据点召回率、基于黄金标准的逻辑形式准确率(LFA)替换掉，采用更加合理且容易的Cypher关键组件验证通过率、Cypher语法驱动通过率作为替代方案，这样可以显著降低对于评估集构造的难度，同时也修正了查询可生成性判断准确率的偏差，这个应该采用图数据库Cypher查询生成专家subAgent的complete字段作为匹配对象。

工作总结[2025-09-11]

1、结合昨天初步改进完整的L3层评估的方案设计进行相应的 评估数据集的构造，这里难点在于构建cypher的关键组件，避免生成完整的gold cypher。然后继续利用钉钉的AI多维表格来实现语料的自动批量打标

2、实践尝试搭建L3评估的管线，目前评估数据端数据处理与数据分析的代码调试没问题了，接下来要把计算指标的方法融入到评估引擎脚本中，这部分还在进一步调试

工作总结[2025-09-12]

1、排查解决了黄金标准加载器函数找不到测试用例的bug，以及评估管线经常出现对导入的clickhouse中间数据未找到Cypher查询的问题

2、当前用代码跑通了L3层评估的几个关键组件脚本，针对subAgent图数据库Cypher查询生成专家设计了三个易评估的指标，具体是围绕查询可生成性判断准确率、Cypher语法通过率、Cypher关键组件验证通过率来设计的评估引擎，目前实现的是一个“初版可运行”版本，但是多个指标的计算结果都有问题，主要难点在于找到这个灵活的“关键”匹配，所以引擎多指标的计算函数的代码调试上还需要进一步优化

------

【2025.09.08–09.12 周工作总结】

- L1评估优化： 修复了多subAgent评估优先级结果混淆的BUG，并优化了报告以精确定位badcase，完成了L1评估管线的收尾工作。
- L3评估方案细化与实现： 重新优化了L3（Cypher生成）评估方案，用（生成性、语法、组件）3个更易于自动化的指标替代了原有的“逻辑形式准确率(LFA)”；并基于新方案搭建并跑通了“初版可运行”的L3评估管线基础设施。

【本周计划】

- 调试并优化L3评估引擎： 集中解决L3评估管线中“关键组件”选取不准、导致多项指标计算结果错误的问题，确保评估引擎的准确性。
- 产出L3评估基线报告： 在评估引擎调试完成后，利用已构造的数据集进行首轮完整的L3层评估，量化当前Agent在Cypher生成上的性能，并生成Baseline报告。

---

工作总结[2025-09-15]

1、解决了“查询可生成性判断”指标一直无法匹配subAgent的complete字段的问题，排查根因是之前提取“裁剪过度”导致 complete 字段在早期筛选阶段丢失。

2、整理L3评估管线的代码框架及现状分析，同王工确认后续开发侧重点，重点围绕核心不变的组件展开评估指标设计

工作总结[2025-09-16]

1、梳理当前L3层评估的指标设计，并同A组讨论确认清楚了当前具体结合了表结构的查询配置subAgent对象为智能工具选择器，所以L3层的评估后续会增加指标，对结合了表结构的智能工具选择器生成的语句进行关键组件匹配评分

2、调整补充L3的评估方案的设计指标，增加并深化对实际结合了项目表结构信息的查询的subagent的效果评估设计

工作总结[2025-09-17]

1、对之前的cypher查询的关键组件匹配的脚本进行重构。结合之前编辑的从clickhouse中获取subAgent的输出的引擎以及spans结构解析等等函数的基础设施来构建L3层新指标“工具选择器”subAgent的输出内容的获取，这部分新增的指标的数据匹配也已经跑通

2、修复在新指标聚合查询准确率下无效问题语料也会被计算查询组件的得分率的bug问题

工作总结[2025-09-18]

1、成功重构并跑通了对智能工具选择器subAgent的评估的指标计算，解决了在这个subAgent下生成的MQL结构存在find与aggregate的两种查询工具的结构的代码不适应的情况

2、所以当前L3层的评估修改后聚焦在查询可生成性判断准确率、MCP工具选择正确性、集合（pms表范围）选择正确性、过滤条件组件匹配度，目前对于如果任务规划subAgent安排了多轮的查询这里还需要单独处理调试

工作总结[2025-09-19]

1、今天也修复了针对智能工具选择器subagent出现多次即多轮查询的情况遗漏的问题，通过处理查询工具、合集、查询条件这些关键组件的聚合策略，实现了即使多轮subagent的复合查询也能进行MQL子智能体的效果评估

2、排查并修复了针对无效问题的输入也会参与得分计算的问题，调试修复了工具和集合匹配逻辑，支持列表形式的多个选项，即通过假设简化认为多轮查询至少有一次查询是能够进入查到目标数据库的表就认为查询路径正确

------

【2025.09.15–09.19 周工作总结】

- L3评估重构与跑通：对L3（MQL生成）评估引擎和语料进行了重构。指标覆盖查询可生成性、工具选择、集合（表范围）选择、过滤条件匹配度4个核心维度。目前19构造样本的L3层初步评估中工具准确率: 52.6%、表召回率: 93.0%，平均查询条件得分: 0.64（仅作参考）
- 多轮复合查询评估实现： 解决了多轮查询 subAgent 匹配缺失问题，新引擎可以非常完整的查出MQL查询到底是在MCP工具、表选取、还是筛选条件上的出现的错误
- L4评估方案更新：重新调整了L4（答案生成）评估方案，将评估逻辑与L3解耦，从 answer 关键词覆盖率出发，而非依赖 L3 的 JSON 返回。将原有的“答案忠实度”更新为更易于实现的“关键词精准匹配”评估

【本周计划】

- 构造L4评估集：开始构建L4评估所需的高质量“问答对”黄金标准数据集，并利用AI多维表格等工具完成标注
- 跑通L4评估管线： 基于新的“关键词精准匹配”方案，同步开发相应的自动化评估脚本。最后输出整个端到端的评估基线（Baseline）报告



---

工作总结[2025-09-22]

1、跟GPT讨论并重新修改和设计了L4，改写了一下L4的评估逻辑为端到端的评分，L4答案层的效果评估与L3的查询解耦，不在关注或断言这些信息是否存在于L3返回的查询结果(JSON)中。将基于L3的答案忠实度改为answer关键词精准匹配，将从数据实际值或者关键字出发，构造精准的问答查询对，判断答案是否覆盖了用户问题中的所有查询点。

2、实践利用PMS的数据库表格数据构建黄金的查询问答对，目前初步构建了二十个涉及不同关键人员、组织和关联信息与边界情况的，并结合AI表格来管理数据。另外也初步尝试了复用L3的查询框架脚本来搭建L4的评估管线

工作总结[2025-09-23]

1、梳理L3评估的当前现状并整理L4更新的指标与实现管线的方案思路，然后与王工确认最终开发路线；以及参与AI周例会

2、重新优化之前使用Gemini帮忙生成的基于PMS数据库的L4黄金数据，但是测试运行的时候发现大量失败案例，主要是数据必须限制在当前项目号下，存在跨项目的问题时候项目助理agent就会很容易回答错误，所以这里又重新结合AI去调整新的黄金语料与标注

工作总结[2025-09-24]

1、整理并优化新的L4数据集的标注，加载使用新的黄金标准来测试L4的新评估指标

2、解决了评估引擎脚本匹配答案关键词遗漏的问题。目前基本调试通过和跑通了L4层的评估指标计算并生成报告

工作总结[2025-09-25]

1、进一步调试解决了L4层评估中对于否定类型的边界问题存在多种回答的匹配遗漏情况，增加了匹配的词汇表和近似关键词计算的方法

2、另外也优化了对于数值统计类型的计算问题匹配方法，之前部分评估会把项目号或者合同号中的数值也计入，这里做了正则的隔离预处理，解决了评估数值错位的问题

3、调研整理了一下如何搭建多AI基础模型的横向评测平台，初步设计了一下横向对比的方案，主要在于需要spans中新增并追踪各个评估层L1、L3和L4的模型attributes字段。这里还需要再整理调研一下目标开源LLM，确定最终的对比对象再与A组那边对接具体实现

工作总结[2025-09-26]

1、调研整理确定了6个合适的开源LLM作为横向对比评估的对象，然后与略哥那边初步对接确认了先新建其中4个LLM的Agent实例。目前相当于已经初步建立起横向评估的平台，但是需要进行全面的多模型横向测试

2、调试修复，因为评估数据文件的变更导致的L1出现报错的问题，现在优化了针对L1、L3、L4各层评估数据的导入模板，以及优化了运行Agent的实例接口URL的统一配置

3、因为L4层的评估管线已经优化通过，所以相当于整个Agent评估的框架都是基本完整的。然后目前初步进行了一步的横向评估实验，调试评估运行的一些报错问题，整个横向评估的报告结果还得进一步实验、调整和总结

工作总结[2025-09-28]

1、在多LLM的横向评估中添加不同模型对各层评测的耗时统计，补充了横向评估中最重要的效率指标的一环。在 ParsedTrace 类中增加聊天时间和持续秒数字段，实现聊天时间提取和解析功能。同时也修改报告模板，增加时间表现部分和各条目的耗时显示

2、排查并发现了新的Qwen-NEXT80B评估效果较差的问题，主要是外部的LLM调用测试评估被限制了并发数和每分钟token数，导致当前Agent工作流经常会有部分subagent会调用失败，从而导致完整的Agent工作流成功率降低。

3、测试发现阿里的魔搭平台免费调用最大卡点主要在每日可调用次数上，硅基流动平台付费调用评估的最大卡点在每分钟token限制上，因为当前针对每层的评估最少都是20个样例以上，所以为了确保评估的所有分布下的样本都能被测试到，最终还是以设置为硅基平台为准，约束评估的批次以解决外部LLM横向评估失真的问题

------

【2025.09.22–09.28 周工作总结】

- L4评估管线跑通： 构建了新的端到端评估数据集并跑通了指标评估的管线，实现基于answer关键词覆盖率的精准评分，解决了关键词匹配、数值统计错位、否定回答匹配遗漏等多个问题。目前15个端到端QA样本的L4层初步评估中答案关键词准确率: 80.00%（Qwen3-32B）

- 横向评测平台搭建： 确定 6 个对比开源 LLM，已初步接入并新建 4 个 Agent 实例Qwen3-32B（本地baseline）、Qwen3-Next-80B-A3B-Instruct（同系列升级）、GLM-4.5-Air（旗舰级对标）、Qwen3-Coder-30B-A3B-Instruct（性价比/差异化）。并新增了模型耗时这一关键效率指标的统计。

- 调用接口横评的问题： 在初步横向评测中，发现硅基的LLM会因API每分钟并发和每分钟token限制，或者接口不稳定导致偶发的工作流某个subagent失败，进而导致外接的整体工作流成功率降低。造成评测结果部分失真的问题。

  - L1层横向待调试目前仅L3和L4的部分评估分析如下（数据比较粗糙，数值仅供对比参考）
  - ![](https://img2024.cnblogs.com/blog/2045416/202509/2045416-20250930084922054-1099628456.png)

  

【本周计划】

- 输出多LLM横向评测报告： 优化调用批次与 token 限制策略，保证 ≥95% 样本能成功跑完；解决中间环节的部分代码问题后，对已确定的多个LLM进行一次更加稳健的、且覆盖L1-L4的横向评估，并输出首份（准确率 + 耗时 + 成功率）综合评测报告。
- 基于评测报告进行模型选型与优化： 根据横向评测结果，分析不同LLM在各评估层级上的优劣势，为项目后续的模型选型提供数据支持，并针对当前Agent工作流的薄弱环节提出优化建议。



---

【上两周工作总结 2025.9.28-9.30/10.9-10.11】

- **多模型横评平台搭建与跑通：**成功搭建并初步跑通了覆盖7+国内外主流与开源LLM的横向评测平台，并解决了外部API连接限制和稳定性的问题。初步评测表明，Qwen系列与当前Agent框架和prompt的适配性优于GLM系列。
-  **评估管线重构与升级：** 对L1/L3/L4评估管线进行了全面改进，L4评估解耦为端到端“关键词匹配”；L1/L3的评估逻辑也完成修正，可分别衡量Agent在**业务相关性判断**和**工具选择**上的能力。
- **评估数据集优化：** 针对前期第一次横向评估效果不明显的问题，重新设计并构建了更具区分度的评估数据集，分层设计了用于鲁棒性测试（L1）和精准度测试（L3/L4）的专用语料。

目前单纯从LLM计算的结果数据上得出的总结是比较符合评估的效果的，从模型尺寸大小、特化方向、架构差异、不同基模这几个方面分析简述如下：

- 单纯的Qwen模型尺寸和架构升级 (Qwen3-Next-80B)，并没有带来效果提升
- 更换不同的架构或者厂商的基模（GLM系列）并没造成明显得分差距，甚至新架构对当前框架和prompt适应性不好
- 从Qwen的QwQ文本理解任务系列升级到coder编程任务系列基本能够带来10%的当前整体效果提升
- 顶级旗舰模型GPT5确实文本理解和Agent能力各个指标基本都是最高水平，但是模型闭源而且中转国外接口偶尔不稳定，另外的国外Gemini模型对当前架构表现出极度不适应

具体的数值和案例如下（横向评估维度、纵向7个不同模型）：

![img](https://img2024.cnblogs.com/blog/2045416/202510/2045416-20251014090459435-1677670171.png)

#### **案例一：基础查询能力 (CaseID C001) - 能力基线**

* **问题**: “查一下项目I-23112109的名称。”
* **挑战**: 简单、直接的单实体单属性查询。
* **综合表现**: **所有模型均能轻松完成**。这表明对于基础的、模式化的查询任务，当前Agent的底层能力是稳定可靠的

#### **案例二：多条件组合查询 (CaseID C013) - 区分点 1**

* **问题**: “由销售工程师李杰负责的马来西亚MY06-PH2-BMS&CCTV改造项目，属于哪个一级销售团队？”
* **挑战**: 从长句中准确抽取出两个不同维度的筛选条件 (`项目名称` + `销售工程师`)。

![img](https://img2024.cnblogs.com/blog/2045416/202510/2045416-20251014090527646-163861778.png)

**案例结论**: 此案例极具价值，它揭示了**所有模型在处理看似简单的多条件组合查询时的普遍性困难**。没有任何一个模型能够完美解决此问题，大部分模型只能抓住其中一个条件，而`GPT-5`和`Gemini`甚至出现了灾难性的失败。**这表明Prompt的适配性鲁棒性是当前系统的巨大短板**。

#### **案例三：复杂嵌套查询 (CaseID C011) - 区分点 2**

* **问题**: “熊瀛担任一级项目经理的I-23112109项目，它的交付团队是哪个？”
* **挑战**: 理解“熊瀛”和“一级项目经理”之间的**归属关系**，并生成针对JSON数组成员的嵌套查询。

![img](https://img2024.cnblogs.com/blog/2045416/202510/2045416-20251014090559238-1185226244.png)

**案例结论**: 这个案例清晰地划分出了模型的**逻辑推理能力等级**。`qwen3-coder-plus` 在此展现了**无可争议的领先优势**，其对复杂逻辑的拆解能力远超其他模型。这强有力地证明了，在需要深度理解数据结构和逻辑关系的场景下，**为代码/逻辑优化的专业模型是不可或缺的**。

初步总结：模型的卡点主要体现在SQL查询层。一个高智商的Agent必须能攻克多条件和嵌套查询这两个堡垒。当前Qwen-coder30B综合比较上都比现在的QwQ32要强，甚至有些地方比GPT5这种通用旗舰模型还好

**【本周计划】**

- **优化并完善评估集数据：** 利用构造的精选高区分度样本，优化 L1/L3 的多轮任务检测逻辑，提高复杂样例评估指标的识别率
- **深度分析结果并提炼优化方向：** 深入分析横评报告，定位当前Agent框架下综合表现最佳的基座模型，并总结各类模型的通用弱点与特定优势，为后续的模型选型、微调或Prompt优化提供明确的数据指导。



---

工作总结[2025-10-13]

1、继续测试新增的旗舰模型GPT5等与Qwen的coder系列模型，基于之前优化了外部模型调用测试的稳定性，目前的横向评估基本都能保证因为连接失败的样本都2个以内，即LLMs的横向多样本的对比评估是足够公正的

2、下午完全输出和整理了所有优化语料下的7个对比模型的各层评估的输出，挑选了有对比意义的输出数据与指标作为比较分析的参考，初步的结论是单纯从LLM计算的结果数据上得出的总结是比较符合评估的效果的，Qwen的coder系列综合比较上都比现在的QwQ32要强，通用旗舰模型效果均衡但是耗时久而且API接口经常不稳定

工作总结[2025-10-14]

1、上午整理评估管线与横向对比的数据与最终的总结文档，挑选合适的典型案例方便AI例会进行讲解与讨论；参加AI例会确定评估效果与后续规划

2、下午归档评估的项目管线，然后调研在当前项目助理Agent中然后进行进一步的强化学习的后续研究

工作总结[2025-10-15]

1、上午把基于项目助理Agent工作流的强化学习研究路线初步整理出一个方案路线文档，主要包含RL的主要目标，引导意图模糊的用户，在一个预定义的“项目问题决策树”上进行推理，最终明确其真实需求。以及RL的状态和动作空间建模的设计方案，然后发给王工审核以确定最终LLM组的RL强化学习路线

2、下午与王工讨论了当前“项目问题决策树”上进行推理的RL方案可行性，以及后续LLM组需要收集更多的可能从模型、框架、输入等层面用RL能提升的地方。另外也与略哥那边确认了当前项目助理Agent优化升级的方向有哪些？以及痛点是什么等等。后续需要综合这些方案去制定LLM组更全面且完善的RL研究方向

工作总结[2025-10-16]

1、综合项目助理Agent的当前完整工作流初步调研整理了所有可能且有意义的用强化学习进行升级优化环节。总共整理从五个工作流节点中整理出八个能应用RL去改进LLM节点的探索能力

2、针对调研梳理的所有RL可应用点进行强化学习的可行性分析，分析不同工作流节点组件进行RL时需要的工作准备以及可能的难点是那些。最后将调研梳理内容初步汇总到强化学习战略分析报告的文档中

工作总结[2025-10-17]

1、针对A组当前工作流的MQL查询不准的痛点，结合调研的八个能应用RL去改进LLM节点的进行了对比并跟GPT进行讨论取舍，最后确定第一个RL方案基于强化学习的“智能查询路由”作为深入的方向，基于此我初步整理出了一个实验方案的文档，包含RL的动作空间、状态空间以及对应的奖励函数与SFT数据的获取的方法

2、整理的方案也跟略哥那边对齐了一下，初步思路可行，但是需要先进行技术试验看看是否补充的路由action对MQL查询结果有提升效果

【2025.10.13–10.17 周工作总结】

- **RL应用可行性分析：** 完成项目助理Agent工作流的强化学习（RL）应用调研，从5个工作流节点中识别出8个潜在可用RL的优化点，如查询路径探索、MQL约束遵循强化训练、RL优化实体识别与问题拆解等等，并做了可行性与难点分析，整理出RL战略综合分析报告。
- **智能路由RL方案设计：** 针对A组MQL查询不准的痛点，与A组对齐了确定首个RL应用方向为“智能查询路由”。已完成实验方案初步设计，定义了动作空间、状态空间与奖励函数。

【本周计划】

- **智能路由技术验证：** 技术试验验证补充路由action到系统prompt中对MQL查询准确性的实际提升效果，并为后续动作空间RL数据构建提供依据。

---

工作总结[2025-10-20]

1、深入研究了当前节点3问题归一化的prompt设计，梳理可能的元素作为state也就是RL方案的输入内容，初步确定state粒度的设计，只保留归一化问题（来自节点3）和已知的已知实体槽位以及最小Schema关系图，通过slots和设计的edges限定合法路径从而保证RL的输入不会过于复杂

2、初步整理研究节点4的NL→MongoDB 生成器的system与user prompt的设计，但是这里还需要进一步划分action的粒度和界限，难点在于router的引导与prompt的规则约束做好边界对齐与处理情况协调，这里尝试了一些可能的组合，目前都发现难以构造合适的action组合，这里还需要尝试进一步技术试验

工作总结[2025-10-21]

1、整理当前MQL查询路由的方案研究切入点，同王工讨论后续技术实验应该关注的对比点，主要是需要找到有区分度的查询数据集，然后通过RL训练专有模型来对比原始LLM节点在生成的MQL查询路径上的优劣，这块还需要深入的进行技术研究

2、下午继续研究设计state与action的组件构造与所有可能的路径组合，这里在设计action上还有个难点在于粒度难界定，如果包含了查询表的主体集合、查询业务的口径分类、再包含几个路径集合之后组合就会非常多。所以这里还需要考虑一下如何简化action空间的设计。以及后续需要基于action去针对性的去构造有对比效果的查询问题集

工作总结[2025-10-22]

1、基于PMS的表结构信息，针对强化学习的action空间构建了初步的20条路径模板作为初期的试验输出选项。另外也完整确定下来了RL的输出format，含Module业务口径（帮助选择预设的业务逻辑），CollectionPath搜索路径

2、调研整理了一部分历史的查询错误数据，并分析总结了后续做RL训练效果对照实验的数据构造板块与方向，主要围绕未发货（contract_bom 业务口径、双lookup链路）yu合同变更（contract→change_log 范式A单跳）yu合同变更（contract→change_log 范式A单跳）这两个旧流程易出错部分的进行数据构造与处理

工作总结[2025-10-23]

1、目前先跑通了仅包含项目助理Agent的节点3、节点4以及mongodb查询的对照组baseline工作流，通过快速针对性的复现MQL生成与查询的LLM节点并微调prompt来生成state状态空间与action动作空间的对照组

2、利用昨天初步手动构造的20个容易出错的MQL查询样本语料进行验证，语料主要围绕未发货清单与合同变更的细节来展开，目前初步对baseline对照组进行了评测，发现20个问题有2个无法生成查询、2个查询路径错误。后续还可以测试实验组用相同20个样例测试Router + Node4，是否生成MQL更准更符合查询路径

3、这对照组的初步情况说明了85%的"MQL有结果"不等于85%的"查询结果正确"，但是目前对于路径的处理还有点问题，后面需要进一步优化对照组的路径提取设计，需要进一步分析路径错误是否导致，返回了错误数据(如S3-02返回合同本身而非变更记录)、返回空结果(如S3-03、S3-08)这些badcase样本的根因

工作总结[2025-10-24]

1、针对昨天实验的生成的结果数据进行了分析，初步可以确认原始baseline（原Agent工作流）确实会困惑于在判断"是否需要$lookup"和"lookup哪些中间表"时最容易失误。特别是针对合同变更记录的相关问题很容易让LLM产生幻觉

2、另外也调试了一下代码判断了确实不是代码的原因产生的偏差，当前从原始Agent工作流提取查询路径path是准确的，能够说明当前baseline的纯prompt结构存在查询推理的缺陷。其次我也初步实验了一下把标注的router作为模拟RL生成查询路径嵌入到当前baseline的prompt中，发现嵌入Router能显著改善LLM的表选择准确率与pass@1

【2025.10.20–10.24 周工作总结】

- **RL方案输入设计：** 在之前的RL调研的方案基础上，进一步确定了智能路由RL方案的最小化输入`State`（归一化问题、Slots、Schema），并基于PMS表结构构建了包含20个路径模板的`Action`空间及输出格式，跟王工对齐了技术实验对比点
- **Baseline对照组实验：** 搭建跑通了对照组最简工作流（节点3+4+MongoDB查询），使用20个MQL易错样本（合同变更、未发货）测试。结果：4/20失败（2个无法生成，2个路径错误）。根因：原始Prompt结构在判断"是否需要$lookup"和"lookup哪些中间表"时最容易失误和产生幻觉
- **RL(模拟)方案验证：** 初步实验将标注的“标注路由路径”作为模拟RL生成的router嵌入Baseline Prompt，结果显示LLM的表选择准确率与`pass@1`从(16/20)提升到(19/20)，空查询返回从3个降为1个，验证了方案可行性。

【本周计划】

- **RL路由对比挑错与消融实验：** 用Router+Node4跑实验组测试其他的问题领域（物料细化、发货申请等），继续挖掘Baseline的路径错误样例，标注并分类典型Badcase，构建并沉淀扩充RL训练集与A/B测试集
- **RL动作空间收敛:** 通过扩充的测试数据集，深入分析路径错误导致的空结果和错误数据的根因，然后测试并简化action粒度与边界，迭代RL的生成推理路径模板

![img](https://img2024.cnblogs.com/blog/2045416/202510/2045416-20251027102714133-1125270624.png)

---

工作总结[2025-10-27]

1、梳理上周实现的模拟RL查询路径进行测试的数据分析问题，总结出目前Baseline（MQL生成）核心问题在于，原始工作流很容易出现表选择错误与$lookup方向错误，例如S3场景(合同变更)涉及2个表关联，Baseline 无法准确判断起始表,随机性强，导致MQL查询返回总是为空

2、所以我通过模拟RL实验组注入的router到prompt中，分析A/B测试结果数据发现可通过`anchor`参数强制指定起始表,消除歧义、通过`target`参数明确跳转目标,确保$lookup方向正确、Node4 Prompt的【Router指导】板块强制执行约束规则。结果LLM的表选择准确率与`pass@1`从(16/20)提升到(19/20)，空查询返回从3个降为1个，这也说明验证了未来RL方案可行性。

工作总结[2025-10-28]

1、上午把之前智能路由的对照组baseline与模拟RL实验组的代码进行了一次模块化重构，目前已经验证模拟的RL生成MQL查询路径是有益的。所以可以先把基于项目助理Agent的RL准备工作先做到这，后面按刘总要求和指导，先去深入的理解，并真正的实验出一个RL模型与学习项目，摸清楚各个RL概念的意义与作用

2、基于今天AI例会的讨论与指导，下午就深入继续之前的RL课程学习RL中的策略学习基础与价值学习基础知识，理解清楚基本框架概念等

工作总结[2025-10-29]

1、今天深入学习了一下RL中价值学习的两种策略网络的更新方法，分别是actor-critic和reinforce两种不同计算TD误差的方式，后者算是前者的N步时序差分的特殊情况，ac除了需要单步奖励的表示还需要状态价值函数值，需要两个函数来作为critic，而reinforce则是需要跑完全局的transition计算全局的奖励，各有特点和应用场景

2、其次也在hugging face的平台上运行并实验训练一个简单的RL且有环境反馈的模型，用stable_baselines3库来实现一个LunarLander的实验，这部分通过调包实现会比较容易一些，但是无法理解ppo库训练了哪些策略模型，所以后续需要拆解调试库里面为什么动作空间的设计是这样以及ppo的策略是如何更新的

工作总结[2025-10-30]

1、继续RL的理论扫盲，今天把基于价值学习的三种主流的优化方法学习理清了一下，分别是多步时序差分、经验回放以及with baseline的降低方差的价值更新方法，总的来说有了这些理论的了解后面来看PPO的前身，也就是TRPO算法能明白为什么强化的策略要这样更新，其次也找了一个很简单的数字解密题来尝试理解贝尔曼的过程

2、理论补充的同时实操，也继续在hugging face的平台上复习第二个Huggy的小狗游戏的案例，虽然案例比较基础，但这次在环境处理上遇到一点点问题，这也从侧面说明RL的环境配置的要求还是比较高的，需要理解环境、策略模型、价值模型等等的RL组件之间的关系以及配置方法，目前这个还在继续实验调试

工作总结[2025-10-31]

1、继续补齐对Q-learning的训练和推理的流程理解，理解在训练Q函数算法实现上MC与TD的区别与应用场景，结合Q-learning的伪代码来尝试实现了编写简单的使用Q-table的强化学习训练过程

2、对于实操过程，调通了之前的Huggy的案例，但是那个动作和状态空间都是库预设的，所以理解不强，但是后面手动练习了Q-learning的基于Q-table的案例，理解了动作、状态与奖励之间的联系，后续就可以把Q-table换成神经网络进行训练练手学习，以扩展到更大的状态空间的案例与项目

【2025.10.27–10.31 周工作总结】

- **路由查询A/B测试验证：** 补完了之前Baseline与模拟RL（注入路由）的对比测试。Baseline在`$lookup`场景下准确率仅为(16/20)。模拟RL通过`anchor`/`target`参数约束，将准确率提升至(19/20)，空查询由3个降至1个，验证了RL路由方案的可行性。并且完成了代码模块化重构，沉淀后续可复用A/B评测骨架
- **RL理论与实操学习进展：** 遵照指导暂停Agent强化摸索，转向RL基础。完成价值学习（Q-learning、AC、REINFORCE）与策略学习理论扫盲；实操HuggingFace（LunarLander、Huggy）案例，并手动推了一遍Q-table算法，掌握状态-动作-奖励机制。

【本周计划】

- **NN-RL模型实践：** 将上周Q-table实践升级，使用神经网络（如DQN）替代Q值表格，在更大状态空间（如CartPole）的环境中进行训练与调优，掌握NN作为函数逼近器在RL中的应用（争取自建一个简单MLP不调包实现DQN）

![img](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251103104440805-1649283708.gif)

---

工作总结[2025-11-03]

1、学习和整理笔记记录深度强化学习的经典方法DQN，并进行相应的技术实验，尝试了利用DQN学习一个价值网络模型来解决状态空间复杂时的案例，如hugging face上新的space invader案例，其中的游戏元素状态空间就是无法穷举的，类似我们当前的项目助理Agent中用户输入的问题类型很难去穷举，所以需要通过价值网络模型去拟合q-table生成Q值

2、也尝试了一下自己搭建一个CNN来作为价值网络进行DQN训练，目前这块还是在RL的环境处理上有比较多的问题需要一步步实验并解决

工作总结[2025-11-04]

1、梳理最近的RL学习与实操进展，然后参与AI小组周例会讨论当前方向与后续的指导方向，探索一下之前弄的意图识别的模型是否可以用价值学习的方法进行RL技术实验

2、继续调试DQN网络的代码跑通SpaceInvader的案例，这块目前已经解决了该案例中图像的处理问题，因为RL需要简化图像游戏的环境，所以在调试环境的时候需要对状态输入进行图像的tensor的维度进行转换，遇到一些bug

3、前面实验的是基于价值的学习方法，然后继续实验基于策略学习的策略梯度方法PG，这里也是一步步手动的构造策略网络和迭代的管线，这块还在调试实验

工作总结[2025-11-05]

1、在前面理清策略学习与价值学习的基础上，寻找并更换来更容易判断自己搭建的神经网络的RL学习效果的案例cartpole作为技术实验对象

2、在选定的案例上分别实验了之前学习的基于价值的方法DQN、基于策略的方法PG（都使用相同的MLP作为模型），得出的效果发现DQN会比PG训练收敛快点，这也响应了当前案例的动作空间较为简单这一现状（PG在奖励采样上效率低、DQN在动作摸索上效率低），所以通过当前简单RL方法实验也验证了当前学习的经验（基于什么样的案例与环境，选择怎么样的RL方法）；后续还可以进一步的学习并实验更复杂的A3C强化学习方法，查看不同的RL的提升效果

工作总结[2025-11-06]

1、继续填补了actor-critic这部分的理论知识和训练代码的实现过程，同样了在之前的LunarLander案例上进行了代码实操，结合效果分析，A2C的方法对于LunarLander这种奖励比较稀疏的情况会收敛很慢，分析因为on-policy对于数据的使用效率比较低，之前DQN只需要500次就可以训练通过，目前的A2C在1000次后依旧奖励值很低，但是A2C的训练速度快

2、另外也补充学习更加复杂和工业化应用较多的PPO算法，这部分还待实操实验。目前除了更前沿的GRPO、ASPO等等没补充，基本RL框架与逻辑梳理差不多了，后续可以尝试挑选真实但是简单的案例进行环境、奖励搭建，并学习如何构造RL的数据，然后训练不同的RL模型

工作总结[2025-11-07]

1、基于昨天学完的actor-critic架构算法，如A2C和PPO算法来手动搭建价值网络模型和策略网络模型（都是使用简单的两层神经网络作为策略模型）跑lunarlander案例，通过这种基础的env包来对比不同算法的特性与适用场景，同时也通过控制变量的方法实现了奖励变化趋势和损失变化的对比功能以及gif效果的对比

2、另外也探索了一下模拟真实场景下的PPO训练方法，打算使用预设的业务逻辑路径作为状态输入，然后设计为一个`64维`的、带噪声的Embedding作为状态，以弥补当前没有训练数据的缺陷，通过这种模拟的方法实验PPO在实际的这种奖励稀疏场景（回合制奖励）下的实现的可行性

3、分析了一下对于之前的基于RoBERTa的实体关系抽取任务中使用RL的方法去强化训练的难度会高一点，因为其中的输出的action空间相比当前查询路径规划任务更大，所以推荐还是以当前基础的表查询路径生成为初步实验目标

【2025.11.03–11.07 周工作总结】

- **RL主流算法实验深化**: 完成DQN、PG、A2C及PPO算法的理论学习与代码实现。在CartPole环境上验证DQN（价值）收敛快于PG（策略）；在LunarLander环境验证A2C（1000次迭代）因On-policy导致数据效率低于DQN（500次迭代），但A2C训练速度确实快；RL主流框架基本摸清了

![img](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251110155234211-1143400303.png)

![img](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251110155254671-307036271.gif)

- **RL应用目标精炼：** 调研分析了实体关系抽取任务相比查询路径任务的这种树action空间复杂度更高，所以后续优先以表查询路径生成为实验主线
- **场景仿真探索**：设计PPO业务路径模拟的简化实验，采用64维噪声embedding替代真实状态输入，搭建稀疏奖励（回合制）RL环境进行了初步模拟的RL技术实验，也第一次遇到了reward hack问题

![img](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251110174325438-1255472005.png)

【本周计划】

- **PPO模拟环境深入实验：** 针对MQL查询路径的稀疏奖励场景，继续实验如何构造更好的PPO模拟训练环境，实验最佳的奖励模型建模方式，**验证PPO在回合制奖励下的可行性。**
- 补充更多前沿RL算法知识和案例的学习，了解各种RL的难点与解决方法

---

工作总结[2025-11-10]

1、梳理上周学习的A2C和PPO算法以及梳理借助模拟环境实验PPO进行路径生成的代码，整理了初步的在RL上探索的一点总结，如在CartPole环境上验证DQN（价值）收敛快于PG（策略）；在LunarLander环境验证A2C（1000次迭代）因On-policy导致数据效率低于DQN（500次迭代）；以及总结了三种利用PPO在我们当前业务中（这种回合制奖励模式下）可能的训练方式

2、选择了初步采用最简单的单回合交互方式，即输入问题语料作为state、输出完整路径作为action，让PPO最多重复五次得到episode奖励作为训练方式，目前已经调试通过了代码实现，不过模拟实验的结果还得进一步分析为什么模型的模拟没有收敛到一次命中

工作总结[2025-11-11]

1、在模拟输入的RL实验上目前状态向量 =路径行为向量 * 冻结线性层(W映射层) + 噪声，目前尝试了许多技术实验让RL训练收敛到一次预测成功。如尝试不改任务设定，改激励结构，让“越早命中”比“反复拿高分不结束”获得更大的回合回报；延长训练episode + 提高探索概率等，但是都无法使得RL的训练收敛。

2、也尝试了通过消融实验方法和过程监控的方式，尝试比对噪声、网络容量等对应RL训练收敛性的影响，发现训练的一次命中率还是太低了，RL的训练，后续考虑补充学习RL训练的一些踩坑和技巧等，也尝试找一下是否有接近我们业务任务的RL训练的开源案例和数据

工作总结[2025-11-12]

1、在模拟RL训练实验上初步的实现了查询的一次命中的收敛，通过调整冻结层+噪声的输入编码方式简化为onehot编码，并优化奖励机制对时间步的惩罚，目前模拟的100次近8成用例可以一次命中答案，这也一部分的说明了PPO在这种回合制的生成任务上有训练的可行性

2、继上次AI例会刘总的要求，尝试结合当前我们真实的业务如表查询路由问题进行最新的RL实现框架设计，目前跟GPT讨论多次，确定AI自动标注样例的方法与初步prompt、真实路由查询的RL框架等等初步的内容以及目前需要补充的准备工作有哪些。后续就按设计来补充数据和必要的工作准备；

3、同时后面也会继续看一下找找是否也有成熟的且业务类似的开源项目与RL数据可以练习的，通过成熟案例来了解RL训练学习的坑和经验有哪些

工作总结[2025-11-13]

1、通过调研找到了与当前业务相似的基于GRPO的text2sql强化训练开源项目sql-rl-gen，同时搜集了部分相关性高的SQL问答数据集。目前初步调试了一下开源RL查询项目的环境，后续尝试能否基于当前完整的项目了解使用强化学习框架训练小模型生成SQL的流程与可能所有的坑点

2、另外，也将之前跑通的MQL查询模拟的RL训练的简单框架添加到当前真实的项目助理Agent的查询业务中，这里是初步的把真实场景需要的设计方案，如完整的状态空间、动作空间以及奖励机制补充完善，另外也优化了对AI自动标注SQL的方法与prompt，所以当前基于真实业务场景的RL准备工作差不多了，后续就可以参考跑通的开源项目来逐步实验当前RL查询路由的数据集准备、环境调试、强化训练

工作总结[2025-11-14]

1、完整跑通开源项目并验证了PPO可以很好的训练单回合制的SQL生成任务。基于IBM开源的sql-rl-gen项目和主流的Spader数据库查询数据集，实现了在现有小模型的基础上，再用“执行结果是否正确”来做强化学习微调。

2、通过跑通强化训练的SQL生成的开源项目，理清了之前的误区，明白PPO算法可以仅在一个单步回合制的episode下完成对于奖励机制的学习收敛，所以之前在模拟路由实验环境中使用在一个样本上重复的查询的长链条方式其实不是必须的。彻底明白简化的RL在一次性生成任务上的实现机制

3、另外也深入的去分析了一下当前项目用到的强化训练的Spader数据集，以及当前项目在处理PPO算法所需结构化输入的数据预处理方法。并且也挑了几个典型的样本进行了实验调试，对比分析RL前后的输出效果对比。后续就可以基于当前所有实现与学习分析的基础上进行我们自己业务的问题的强化学习的数据集构建，以及PPO的训练环境的进一步改进完善，特别是对于奖励机制的进一步实验完善

【2025.11.10–11.14 周工作总结】

- **同类开源RL项目验证：** 找到IBM开源的sql-rl-gen项目+Spader数据集5693条SQL，完整跑通基于flan-t5的PPO强化训练SQL生成流程；理清关键误区——PPO可以在单步回合制episode下完成学习收敛，不需要之前强行模拟的在单样本上搞长链条重复查询；深入分析Spader数据集预处理方法和RL前后效果对比
- **PPO模拟训练收敛：** 也解决了之前模拟的PPO训练不收敛问题，通过简化输入(one-hot)与优化奖励(时间惩罚)，在100次模拟测试中实现~80%的单次命中率。
- **MQL-RL框架设计：** 完成MQL查询路由的真实RL框架设计，已基于之前的验证与模拟重新定义了状态/动作空间、奖励机制及AI自动标注路由的Prompt，并完成初步训练代码集成。

【本周计划】

- **自建业务RL数据集**: 参考sql-rl-gen经验，构建MQL查询路由的RL训练数据集

- 启动真实业务场景（查询路由）的强化训练实验，在过程中完善PPO训练环境特别是奖励机制设计

  

---

工作总结[2025-11-17]

1、基于上周找到并跑通的开源项目sql-rl-gen继续深入分析其项目构建的流程和原理，比如RL训练中的observation_list、data_list_to_pass、columns_names_mismatch的数据类型意义与起到作用等等。其中也发现了一些当前开源项目的缺陷，通过借助项目中的评估引擎脚本我构建了基模与rl训练后模型的A/B测试分析模块，发现当前项目的环境奖励机制实际上是有缺陷的。很多SQL结果的评判指标都没有用上，原项目似乎是要借助于更高级的Eureka机制去动态构建奖励标准

2、不过Eureka这种动态奖励的超前设计对于我们的项目业务来说不是必要的，所以在经过深入PPO训练数据利用的解析之后，我给项目重构了更合适的奖励机制，并重新小规模训练了基于spider的PPO策略模型（因为当前4090在这个RL项目上训练很慢，大约半个小时只能跑100个step）

3、完整地优化配置并修改了项目sql-rl-gen训练的代码，将所有的T5模型组件、输入prompt模板都放到本地的27服务器上，目前这个开源项目基本吃透，而且训练、评估和对比分析基本都我优化完善了。后续不管是表查询路由还是公司自己业务的SQL生成都可以直接复用和升级

工作总结[2025-11-18]

1、上午把之前跑通的sql-rl-gen训练的结果与我们之前的RL训练进行了对比分析，区别是训练对象表现形式不同（单回合无环境交互 VS 重复查询的长链条交互）、输出不同（完整SQL生成任务 VS 查询路径选择分类任务）、reward计算不同（对比SQL查询结果差异 VS 对比路由与标注的差异）

2、然后也跑了2000step周的sql-rl-gen强化学习训练模型与基模的对比分析，发现虽然目前训练是没有问题的，但是reward并没有明显上升的趋势（即退化为SFT的效果），怀疑可能三点原因，1、训练step2000少于了样本量5693的倍数；2、奖励机制还是有缺陷；3、没有预先SFT冷启动导致的PPO训练不稳定

3、下午就回归到MQL表查询路由RL训练的板块，基于之前理解了的text2SQL的强化学习训练的基础来尝试构建我们自己业务的数据集，这里重新调整利用AI帮忙标注路由数据的提示词，不过这里需要解决标注提示词过长的问题，也就是需要和周晖那边确定动态注入的表结构提示词的方法怎么在这里去使用

工作总结[2025-11-19]

1、实验使用昨天从周晖那边拿到的历史MQL查询的数据以及自己生成的一小部分数据（目前有96条）进行AI自动标注，先利用这部分“正确标注”数据来调试跑通我们自己本地业务的训练环境和代码

2、目前在实验试跑Roberta模型进行路由分类强化学习训练时候遇到的第一个问题是，输入的token窗口不够的问题，Roberta极限是512个token，但是当前输入（问题50左右+表结构481）就已经超出了最大的上下文窗口，这部分现在初步的方案是先优化table schema，后续可以参考上一个开源项目sql-rl-gen对T5模型（也是512窗口，输入为{system}+{tables}+{question}）的输入进行tokenizer的预处理

3、初步调试通了基于MQL查询路由的强化学习训练，因为当前任务是直接匹配路径是否学准了，奖励路径较短反馈快，所有目前在4090上训练Roberta（目前只有96个样本）跑20000个step大约只需要半个小时。不过测试训练的指标结果还不行，还是之前那个问题reward hacking，模型的强化学习一直钻奖励的漏子，没有完整的学到路径决策树的模式。这部分跑通了后续就可以不断实验优化迭代

工作总结[2025-11-20]

1、继续在当前小数据集样本上调试训练，对比分析各组件训练的曲线变化，发现当前PPO训练表查询路由的卡点在于，基于标准答案路径的组件匹配奖励机制难适配数据分布的真实情况，模型可能逮着一个“容易”得奖的组件使劲薅（例如单跳容易，模型就猛学单跳有关的组件奖励，而多跳的更多组件没照顾到），反而整体的准确率不高

2、后续奖励机制可能还是要实验换成简单而直接的“生成值得信赖的 SQL 语句”，而不仅是语法组件正确的SQL，因为大模型困难不在于生成表面SQL的技术，而是SQL的执行逻辑。只要这个路由决策树逻辑训练通了，后续任意带逻辑的生成任务都可以用这种业务逻辑私有模型+大模型生成的机制

工作总结[2025-11-21]

1、利用之前跑通的sql-rl-gen开源项目上实验了一下奖励机制目标明确但奖励值稀疏的RL训练，这里设置了10000个step跑了一天都没跑完（这说明这种基于最终查询结果的RL训练链路过长会导致训练速度极慢），当前仅一半的训练记录也展示了新的训练目标会出现批量成功、失败的情况（即明确但稀疏的奖励会导致训练极不稳定）

2、同时今天也在基于我们自己的表查询业务实现了一下新的强化学习训练机制，即直接从路由对比结果获取奖励到mongodb返回查询结果的反馈中获取奖励，借助使用之前实验过的模拟查询路由对比分析管线，将强化训练下的Roberta生成的查询路由嵌入到“mongodb查询生成子Agent”的系统提示词中以获得改进提示词后的完整流程的查询结果，目前这块还待调试代码，并实现完整的200step的RL训练

3、在我们自己业务RL项目和开源项目的多次实验的背景下，深入的梳理整理了一下当前的逐步摸索RL的训练框架，以及不断优化之后的RL项目架构，并整成markdown文档记录下来

【2025.11.17–11.21 周工作总结】

- **MQL路由训练：** 构建96条AI自动标注数据，调试通Roberta路由分类强化训练（20000步半小时）；发现两大问题
  - ①小模型token窗口512限制（问题50+表结构481已超限），优化table schema暂时解决；
  - ②reward hacking严重，模型专薅"单跳"等简单组件奖励，多跳组件没学到，整体准确率不行
- **sql-rl-gen项目技术实验：** 深度优化`sql-rl-gen`项目，利用T5模型实验基于“最终执行结果”的稀疏奖励（链路长，100step花半小时）
  - 在4090服务器上跑了32小时的PPO训练的结果，奖励收敛到-0.5到1之间，发现75000步后有一个aha moment（模型不再出现**查空表名、Syntax Error、危险指令**的负reward情况），后面只剩下1与-0.5（即会的已会，不会的还是不会）——猜测可能是复杂SQL嵌套逻辑过难、模型过小

![img](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251124094007993-1872243297.png)

- **奖励机制重构：** 转向新机制：将RL生成的路由嵌入MongoDB查询生成子Agent Prompt，直接以MongoDB查询反馈为奖励信号。让模型学SQL执行逻辑而非答案组件，目前代码待调试；已完成RL训练架构文档沉淀。

  ![img](https://img2024.cnblogs.com/blog/2045416/202511/2045416-20251124150724037-673972323.png)

【本周计划】

- **新环境奖励机制验证**: 调试完成基于mongodb查询结果反馈的RL训练，验证能否解决reward hacking问题及提升复杂多跳查询
  - 解决“最终执行结果”的好坏自动评估的问题
  - 构造查询问题与标注路由的数据集200条